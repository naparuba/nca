# =============================================================================
# SP√âCIFICATION TECHNIQUE : Syst√®me NCA Diffusion de Chaleur avec Obstacles
# =============================================================================
# Fichier de sp√©cification pour acc√©l√©rer l'analyse IA du syst√®me 6__*py
# G√©n√©r√© automatiquement par analyse en profondeur du code source
# Date: 2024-12-29

## ARCHITECTURE G√âN√âRALE DU SYST√àME

### Vue d'ensemble
Le syst√®me impl√©mente un Neural Cellular Automaton (NCA) optimis√© pour apprendre la diffusion de chaleur en pr√©sence d'obstacles. Il s'agit d'une version avanc√©e avec optimisations de performance et support complet des obstacles.

### Fichiers principaux
- `6__nca_heat_diffuse_fast_mode.py` : Script d'entra√Ænement principal
- `6__visualize_heat_diffuse_fast_mode.py` : Script de visualisation avanc√©e

### Paradigme architectural
- **S√©paration des responsabilit√©s** : Simulateur physique / Mod√®le neuronal / Entra√Æneur / Visualiseur
- **Configuration centralis√©e** : Classe `Config` pour tous les hyperparam√®tres
- **Mode dual** : Interactif (temps r√©el) vs Non-interactif (sauvegarde)
- **Support multi-seed** : Seeds s√©par√©es pour entra√Ænement et visualisation

## COMPOSANTS PRINCIPAUX

### 1. Configuration (Classe Config)
**R√¥le** : Centralise tous les param√®tres du syst√®me pour faciliter les exp√©rimentations

**Param√®tres cl√©s** :
```python
DEVICE: str                    # "cuda" ou "cpu" auto-d√©tect√©
SEED: int                      # Seed principal (d√©faut: 123)
GRID_SIZE: int                 # Taille grille NxN (d√©faut: 16)
SOURCE_INTENSITY: float        # Intensit√© sources chaleur (d√©faut: 1.0)

# Entra√Ænement
N_EPOCHS: int                  # Nombre √©poques (d√©faut: 100)
NCA_STEPS: int                 # Horizon temporel multi-step (d√©faut: 20)
LEARNING_RATE: float           # Taux apprentissage (d√©faut: 1e-3)
BATCH_SIZE: int                # Taille batch (d√©faut: 4)

# Architecture mod√®le
HIDDEN_SIZE: int               # Taille couches cach√©es (d√©faut: 128)
N_LAYERS: int                  # Nombre couches (d√©faut: 3)

# Obstacles
MIN_OBSTACLES: int             # Nombre min obstacles (d√©faut: 1)
MAX_OBSTACLES: int             # Nombre max obstacles (d√©faut: 3)
MIN_OBSTACLE_SIZE: int         # Taille min obstacle (d√©faut: 2)
MAX_OBSTACLE_SIZE: int         # Taille max obstacle (d√©faut: 4)

# Optimisations NOUVELLES
USE_OPTIMIZATIONS: bool        # Active optimisations (d√©faut: True)
USE_SEQUENCE_CACHE: bool       # Cache s√©quences (d√©faut: True)
USE_VECTORIZED_PATCHES: bool   # Extraction vectoris√©e (d√©faut: True)
CACHE_SIZE: int                # Taille cache (d√©faut: 200)
```

**Arguments ligne de commande support√©s** :
- `--seed` : Seed d'entra√Ænement
- `--vis-seed` : Seed de visualisation (ind√©pendante)
- `--epochs` : Nombre d'√©poques
- `--grid-size` : Taille de la grille
- `--batch-size` : Taille des batches

### 2. Simulateur Physique (Classe DiffusionSimulator)
**R√¥le** : G√©n√®re la v√©rit√© terrain (simulation physique) que le NCA doit apprendre

**Algorithme de diffusion** :
- Kernel de convolution 3x3 uniforme (moyenne des 9 voisins)
- Simule l'√©quation de diffusion de chaleur discr√©tis√©e
- Conditions de Dirichlet pour les sources (temp√©rature fixe)
- Obstacles bloquent compl√®tement la diffusion

**G√©n√©ration d'obstacles** :
- Placement al√©atoire avec √©vitement de la source
- Tailles variables (carr√©s de 2x2 √† 4x4)
- Nombre variable (1 √† 3 obstacles par grille)
- 50 tentatives max pour placement valide

**M√©thodes cl√©s** :
```python
generate_obstacles(size, source_pos, seed) -> torch.Tensor
step(grid, source_mask, obstacle_mask) -> torch.Tensor
generate_sequence(n_steps, size, seed) -> (List[Tensor], Tensor, Tensor)
```

### 3. Mod√®le NCA (Classe ImprovedNCA)
**R√¥le** : R√©seau neuronal qui apprend les r√®gles de mise √† jour locales

**Architecture avanc√©e** :
- Input: Patch 3x3 (9 valeurs) + info source (1) + info obstacle (1) = **11 features**
- Couches cach√©es : `n_layers` √ó (`Linear` ‚Üí `BatchNorm1d` ‚Üí `ReLU` ‚Üí `Dropout(0.1)`)
- Output: Delta dans [-0.1, 0.1] via `Tanh` + scaling
- Stabilit√© renforc√©e par normalisation et dropout

**Am√©liorations vs version classique** :
- Support natif des obstacles dans l'input
- BatchNorm pour stabilit√© d'entra√Ænement
- Dropout pour r√©gularisation
- Architecture flexible (param√©trable)
- Delta limit√© pour √©viter explosions

### 4. Syst√®mes de Mise √† Jour (NCAUpdater vs OptimizedNCAUpdater)

#### NCAUpdater (Version standard)
- Extraction patches par boucles Python
- Traitement s√©quentiel des positions
- Simple mais lent

#### OptimizedNCAUpdater (Version optimis√©e - NOUVEAU)
- **Extraction vectoris√©e** via `F.unfold()`
- Traitement parall√®le sur GPU
- Performance drastiquement am√©lior√©e
- Zero-copy operations quand possible

**Diff√©rence de performance** : ~10-50x plus rapide selon la taille de grille

### 5. Syst√®me d'Entra√Ænement Multi-Modal

#### Cache de S√©quences Optimis√© (OptimizedSequenceCache - NOUVEAU)
**Innovation majeure** : Pr√©-g√©n√®re et stocke toutes les s√©quences d'entra√Ænement

**Avantages** :
- √âlimination du overhead de g√©n√©ration pendant l'entra√Ænement
- Donn√©es stock√©es directement sur GPU
- M√©lange p√©riodique pour vari√©t√©
- Acc√®s cyclique O(1)

#### NCATrainer (Version hybride)
**Modes de fonctionnement** :
- **Standard** : G√©n√©ration √† la vol√©e (comme versions pr√©c√©dentes)
- **Optimis√©** : Utilise cache + updater vectoris√©

**Fonctionnalit√©s avanc√©es** :
- Gradient clipping automatique (max_norm=1.0)
- Scheduler cosine pour learning rate
- Weight decay (1e-4) pour r√©gularisation
- Perte multi-step (moyenne sur horizon temporel)
- Historique d√©taill√© (loss + learning rate)

**Algorithme d'entra√Ænement** :
```
Pour chaque √©poque:
  Pour chaque batch:
    - Initialise grille vide + sources
    - Pour NCA_STEPS √©tapes:
      * Applique NCA une fois
      * Calcule loss MSE vs target
      * Accumule loss
    - Backprop sur loss moyenne
    - Clip gradients
    - Update param√®tres
```

### 6. Syst√®me de Visualisation Avanc√© (NCAVisualizer)

**Modes de fonctionnement** :
- **Interactif** : Animation temps r√©el (Qt5Agg/TkAgg)
- **Sauvegarde** : G√©n√©ration fichiers pour post-traitement

**Donn√©es sauvegard√©es par frame** :
```python
{
    'step': int,
    'nca_grid': np.ndarray,      # √âtat NCA
    'target_grid': np.ndarray,   # √âtat cible
    'obstacle_mask': np.ndarray, # Masque obstacles
    'source_mask': np.ndarray,   # Masque sources
    'title': str
}
```

**M√©triques g√©n√©r√©es** :
- √âvolution perte (√©chelle log)
- √âvolution learning rate (√©chelle log)
- Sauvegarde mod√®le avec m√©tadonn√©es compl√®tes

## SCRIPT DE VISUALISATION AVANC√âE

### Fonctionnalit√©s du visualiseur (6__visualize_heat_diffuse_fast_mode.py)

**Support multi-seed** :
- D√©tection automatique r√©pertoires par pattern
- Support ancien format + nouveau format avec seed
- Arguments : `--seed`, `--output-dir`, `--fps`

**Analyses g√©n√©r√©es** :
1. **GIF anim√© 4 panneaux** :
   - NCA en temps r√©el
   - Simulation cible (statique √©tat final)
   - Diff√©rence absolue |NCA - Cible|
   - Obstacles & sources (composite RGB)

2. **Comparaison statique multi-√©tapes** :
   - √âtapes cl√©s : [0, 10, 20, final]
   - M√©triques par √©tape (MSE, erreur max)
   - Support obstacles

3. **Analyse de convergence** :
   - MSE au cours du temps (√©chelle log)
   - Erreur maximale au cours du temps
   - Couverture d'obstacles (si applicable)

**Gestion des obstacles dans la visualisation** :
- D√©tection automatique pr√©sence obstacles
- Codage couleur : Gris (obstacles), Rouge (sources), Blanc cass√© (libre)
- M√©triques sp√©cialis√©es (nombre obstacles, couverture)

## OPTIMISATIONS DE PERFORMANCE

### 1. Cache de S√©quences Pr√©-calcul√©es
- **Impact** : √âlimine 80%+ du temps de g√©n√©ration
- **M√©moire** : ~200 s√©quences stock√©es sur GPU
- **Strat√©gie** : G√©n√©ration une fois, r√©utilisation cyclique

### 2. Extraction Vectoris√©e des Patches
- **Technique** : `F.unfold()` remplace boucles Python
- **Impact** : 10-50x acc√©l√©ration selon taille grille
- **GPU-natif** : Op√©rations enti√®rement parall√©lis√©es

### 3. D√©tection Automatique Backend Matplotlib
- **Fallback intelligent** : Qt5Agg ‚Üí TkAgg ‚Üí Agg (sauvegarde)
- **Compatibilit√©** : Windows, Linux, environnements headless

### 4. Architecture Modulaire
- **Updaters interchangeables** : Standard vs Optimis√©
- **Configuration centralis√©e** : Exp√©rimentations faciles
- **S√©paration concerns** : Physique / Neural / Viz

## FORMATS DE DONN√âES

### Structure r√©pertoires de sortie
```
__6__nca_outputs_heat_diffuse_fast_mode_seed_{SEED}/
‚îú‚îÄ‚îÄ animation_avant_entra√Ænement.npy
‚îú‚îÄ‚îÄ animation_apr√®s_entra√Ænement.npy
‚îú‚îÄ‚îÄ gif_animation_avant_entra√Ænement.gif
‚îú‚îÄ‚îÄ gif_animation_apr√®s_entra√Ænement.gif
‚îú‚îÄ‚îÄ static_animation_avant_entra√Ænement.png
‚îú‚îÄ‚îÄ static_animation_apr√®s_entra√Ænement.png
‚îú‚îÄ‚îÄ convergence_avant_entra√Ænement_seed_{SEED}.png
‚îú‚îÄ‚îÄ convergence_apr√®s_entra√Ænement_seed_{SEED}.png
‚îú‚îÄ‚îÄ training_metrics.png
‚îî‚îÄ‚îÄ nca_model.pth
```

### Format sauvegarde mod√®le
```python
{
    'model_state_dict': Dict,        # Poids r√©seau
    'config': Config,                # Configuration compl√®te
    'training_seed': int,            # Seed entra√Ænement
    'visualization_seed': int,       # Seed visualisation
    'loss_history': List[float],     # Historique perte
    'lr_history': List[float]        # Historique learning rate
}
```

## POINTS TECHNIQUES AVANC√âS

### Gestion de la Stabilit√©
- **Gradient clipping** : Limite √† norm=1.0
- **Delta scaling** : Facteur 0.1 pour changements graduels
- **Clamping** : Valeurs dans [0,1] apr√®s chaque update

### Support Multi-GPU
- **Auto-d√©tection** : `torch.cuda.is_available()`
- **Tensors sur device** : Transfert automatique
- **G√©n√©rateurs avec seed** : Reproductibilit√© GPU

### Gestion M√©moire
- **Clonage explicite** : √âvite modifications accidentelles
- **Cache GPU-resident** : √âvite transfers CPU‚ÜîGPU
- **Cleanup automatique** : `plt.close()` syst√©matique

## POINTS D'EXTENSION

### Facilit√©s d'exp√©rimentation
1. **Nouveaux obstacles** : Modifier `generate_obstacles()`
2. **Nouvelles architectures** : H√©riter de `ImprovedNCA`
3. **Nouvelles m√©triques** : √âtendre `NCAVisualizer`
4. **Nouveaux optimiseurs** : Modifier `NCATrainer.__init__()`

### Hyperparam√®tres critiques
- `NCA_STEPS` : Balance apprentissage vs stabilit√©
- `CACHE_SIZE` : Balance m√©moire vs vari√©t√©
- `DELTA_SCALE` : Contr√¥le vitesse convergence
- `HIDDEN_SIZE` : Capacit√© mod√®le vs overfitting

## DEBUGGING & DIAGNOSTICS

### Signaux de sant√© syst√®me
- **Mode optimis√© activ√©** : Messages "üöÄ Utilisation updater optimis√©"
- **Cache initialis√©** : Messages "‚úÖ Cache des s√©quences cr√©√©"
- **Backend d√©tect√©** : Messages d√©tection matplotlib

### M√©triques de performance
- **Temps par √©poque** : Devrait diminuer avec optimisations
- **Convergence loss** : Doit d√©cro√Ætre r√©guli√®rement
- **Stabilit√© gradients** : V√©rifier via gradient clipping

### Points de d√©faillance communs
1. **M√©moire GPU insuffisante** : R√©duire `CACHE_SIZE` ou `GRID_SIZE`
2. **Obstacles trop grands** : V√©rifier `MAX_OBSTACLE_SIZE < GRID_SIZE//2`
3. **Backend matplotlib** : Probl√®mes affichage selon environnement

## COMPARAISON AVEC VERSIONS PR√âC√âDENTES

### Nouvelles fonctionnalit√©s v6
- ‚úÖ **Support obstacles complet** (g√©n√©ration + visualisation)
- ‚úÖ **Cache s√©quences optimis√©** (gain performance majeur)
- ‚úÖ **Extraction patches vectoris√©e** (GPU-natif)
- ‚úÖ **Seeds s√©par√©es** (entra√Ænement vs visualisation)
- ‚úÖ **Architecture modulaire** (updaters interchangeables)
- ‚úÖ **Visualisation 4 panneaux** (NCA + Cible + Diff + Obstacles)
- ‚úÖ **Sauvegarde m√©tadonn√©es** (reproductibilit√© compl√®te)

### R√©trocompatibilit√©
- ‚úÖ Interface arguments ligne de commande pr√©serv√©e
- ‚úÖ Format sorties compatible (ajouts non-breaking)
- ‚úÖ Fallback mode standard si optimisations d√©sactiv√©es

---
**Note** : Cette sp√©cification couvre l'√©tat du syst√®me au 2024-12-29.
Pour modifications futures, mettre √† jour cette spec en cons√©quence.

# Sp√©cification : Neural Cellular Automaton - Diffusion de Chaleur avec Obstacles (Mode Optimis√©)

## Vue d'ensemble

Ce projet impl√©mente un **Neural Cellular Automaton (NCA)** optimis√© pour apprendre la diffusion de chaleur en pr√©sence d'obstacles. Le syst√®me combine simulation physique, apprentissage automatique et optimisations de performance.

### Objectif
Entra√Æner un NCA √† reproduire fid√®lement le comportement de diffusion thermique d'un simulateur physique, tout en g√©rant des obstacles qui bloquent la propagation de la chaleur.

## Architecture du Syst√®me

### 1. Configuration Centralis√©e (`Config`)

**Param√®tres de base :**
- `DEVICE` : GPU/CPU automatiquement d√©tect√©
- `SEED` : Graine al√©atoire configurable (d√©faut: 123)
- `GRID_SIZE` : Taille de la grille (d√©faut: 16x16)
- `SOURCE_INTENSITY` : Intensit√© de la source de chaleur (1.0)

**Param√®tres d'entra√Ænement :**
- `N_EPOCHS` : 100 √©poques
- `NCA_STEPS` : 20 √©tapes temporelles par s√©quence
- `LEARNING_RATE` : 1e-3 avec AdamW
- `BATCH_SIZE` : 4 s√©quences par batch

**Param√®tres de visualisation :**
- `PREVIS_STEPS` : 30 √©tapes (animation pr√©-entra√Ænement)
- `POSTVIS_STEPS` : 50 √©tapes (animation post-entra√Ænement)
- D√©tection automatique du mode interactif vs sauvegarde

**Param√®tres des obstacles :**
- `MIN_OBSTACLES` / `MAX_OBSTACLES` : 1-3 obstacles par grille
- `MIN_OBSTACLE_SIZE` / `MAX_OBSTACLE_SIZE` : Carr√©s de 2x2 √† 4x4

**Optimisations de performance :**
- `USE_OPTIMIZATIONS` : Active les optimisations (d√©faut: True)
- `USE_SEQUENCE_CACHE` : Cache de 200 s√©quences pr√©-calcul√©es
- `USE_VECTORIZED_PATCHES` : Extraction vectoris√©e des patches
- `USE_MIXED_PRECISION` : Pr√©cision mixte (d√©sactiv√© par d√©faut)

### 2. Simulateur Physique (`DiffusionSimulator`)

**M√©thode de simulation :**
- Convolution 2D avec noyau 3x3 uniforme (1/9 pour chaque cellule)
- Simule l'√©quation de diffusion de chaleur discr√©tis√©e
- Kernel : `torch.ones((1, 1, 3, 3)) / 9.0`

**Gestion des obstacles :**
- G√©n√©ration al√©atoire d'obstacles rectangulaires
- V√©rification de non-chevauchement avec les sources
- Obstacles bloquent compl√®tement la diffusion (valeur fix√©e √† 0.0)

**Conditions aux limites :**
- Sources de chaleur : conditions de Dirichlet (valeur fixe)
- Obstacles : conditions de Dirichlet (temp√©rature = 0)
- Bords : padding replicatif lors de la convolution

### 3. Architecture du NCA (`ImprovedNCA`)

**Entr√©e du r√©seau :**
- Patch 3x3 autour de chaque cellule (9 valeurs)
- Feature "est source" (1 valeur bool√©enne)
- Feature "est obstacle" (1 valeur bool√©enne)
- **Total : 11 features d'entr√©e**

**Architecture du r√©seau :**
- R√©seau fully-connected avec 3 couches cach√©es
- 128 neurones par couche cach√©e
- Activation ReLU + BatchNorm1d + Dropout(0.1)
- Sortie : 1 valeur (delta √† appliquer)
- Facteur d'√©chelle : 0.1 (stabilit√© d'entra√Ænement)

**Contraintes de sortie :**
- Delta dans [-0.1, 0.1] via Tanh + scaling
- Clamp final des valeurs dans [0.0, 1.0]

### 4. Syst√®me de Mise √† Jour

**Version Standard (`NCAUpdater`) :**
- Boucles Python pour extraction des patches
- Traitement batch des patches valides
- Skip automatique des obstacles

**Version Optimis√©e (`OptimizedNCAUpdater`) :**
- Extraction vectoris√©e via `F.unfold()`
- Op√©rations GPU natives (pas de boucles Python)
- Gain de performance significatif

### 5. Syst√®me d'Entra√Ænement (`NCATrainer`)

**Optimiseur :**
- AdamW avec weight decay (1e-4)
- CosineAnnealingLR scheduler
- Gradient clipping (max_norm=1.0)

**Fonction de perte :**
- MSE entre s√©quence pr√©dite et s√©quence cible
- Accumulation sur les 20 √©tapes temporelles
- Moyennage pour la perte finale

**Cache de s√©quences optimis√© (`OptimizedSequenceCache`) :**
- Pr√©-g√©n√©ration de 200 s√©quences d'entra√Ænement
- Stockage direct sur GPU
- M√©lange p√©riodique pour la vari√©t√©
- Acc√®s cyclique aux s√©quences

### 6. Syst√®me de Visualisation (`NCAVisualizer`)

**Mode interactif :**
- D√©tection automatique des backends (Qt5Agg/TkAgg)
- Animation temps r√©el avec matplotlib
- Comparaison NCA vs simulation cible + obstacles

**Mode sauvegarde :**
- Export des animations en fichiers .npy
- G√©n√©ration de GIFs via script s√©par√©
- M√©triques d'entra√Ænement sauvegard√©es

## Arguments de Ligne de Commande

**Script principal (`__6__nca_heat_diffuse_fast_mode.py`) :**
```bash
--seed INT          # Graine d'entra√Ænement (d√©faut: 123)
--vis-seed INT      # Graine de visualisation (d√©faut: 3333)  
--epochs INT        # Nombre d'√©poques (d√©faut: 100)
--grid-size INT     # Taille de grille (d√©faut: 16)
--batch-size INT    # Taille de batch (d√©faut: 4)
```

**Script de visualisation (`6__visualize_heat_diffuse_fast_mode.py`) :**
```bash
--seed INT          # Seed sp√©cifique √† visualiser
--output-dir STR    # R√©pertoire de sortie sp√©cifique
--fps INT           # Images par seconde des GIFs (d√©faut: 8)
```

## Fichiers de Sortie

**Structure du r√©pertoire de sortie :**
```
__6__nca_outputs_heat_diffuse_fast_mode_seed_{SEED}/
‚îú‚îÄ‚îÄ animation_avant_entra√Ænement.npy      # Animation pr√©-entra√Ænement
‚îú‚îÄ‚îÄ animation_apr√®s_entra√Ænement.npy      # Animation post-entra√Ænement
‚îú‚îÄ‚îÄ gif_animation_avant_entra√Ænement.gif  # GIF pr√©-entra√Ænement
‚îú‚îÄ‚îÄ gif_animation_apr√®s_entra√Ænement.gif  # GIF post-entra√Ænement
‚îú‚îÄ‚îÄ static_animation_avant_entra√Ænement.png # Image statique pr√©
‚îú‚îÄ‚îÄ static_animation_apr√®s_entra√Ænement.png # Image statique post
‚îú‚îÄ‚îÄ convergence_avant_entra√Ænement_seed_{SEED}.png  # Graphique convergence pr√©
‚îú‚îÄ‚îÄ convergence_apr√®s_entra√Ænement_seed_{SEED}.png  # Graphique convergence post
‚îú‚îÄ‚îÄ training_metrics.png                  # M√©triques d'entra√Ænement
‚îî‚îÄ‚îÄ nca_model.pth                        # Mod√®le sauvegard√©
```

## Fonctionnalit√©s Avanc√©es

### Optimisations de Performance
1. **Cache de s√©quences** : √âvite la recomputation des s√©quences d'entra√Ænement
2. **Extraction vectoris√©e** : Remplace les boucles Python par des op√©rations GPU
3. **Batch processing** : Traitement group√© des patches pour l'efficacit√©

### Reproductibilit√©
- Seeds s√©par√©s pour entra√Ænement et visualisation
- Configuration centralis√©e des param√®tres
- Nommage des r√©pertoires avec seed

### Robustesse
- D√©tection automatique du mode d'affichage
- Gestion d'erreurs pour les backends matplotlib
- Gradient clipping et r√©gularisation
- Normalisation par batch

## Algorithme d'Entra√Ænement

1. **Initialisation** : Grille vide avec sources activ√©es
2. **D√©roulement temporel** : 20 √©tapes NCA avec accumulation de perte
3. **Optimisation** : Backpropagation + gradient clipping
4. **Mise √† jour** : Param√®tres du r√©seau via AdamW
5. **Scheduling** : R√©duction progressive du learning rate

## Contraintes Physiques

- **Sources** : Valeur fixe (1.0) maintenue √† chaque √©tape
- **Obstacles** : Valeur fixe (0.0) - bloquent la diffusion
- **Bords** : Gestion automatique via padding replicatif
- **Valeurs** : Clamp dans [0.0, 1.0] pour la stabilit√©

## M√©triques et Validation

- **Perte MSE** : Comparaison pixel par pixel avec simulation cible
- **Convergence visuelle** : Animations avant/apr√®s entra√Ænement
- **Stabilit√©** : Gradient clipping et monitoring du learning rate
- **Performance** : Temps d'entra√Ænement avec/sans optimisations

