from pathlib import Path
from typing import Dict, Any, List

import numpy as np
import torch
from matplotlib import pyplot as plt

from config import CONFIG
from train import ImprovedNCA, simulator, OptimizedNCAUpdater


class ProgressiveVisualizer:
    """
    Syst√®me de visualisation avanc√© pour l'apprentissage modulaire.
    G√©n√®re des animations et graphiques comparatifs par √©tape.
    """
    
    
    def __init__(self):
        self.frame_data = {}  # Donn√©es par √©tape
    
    
    def visualize_stage_results(self, model: ImprovedNCA, stage_nb: int) -> None:
        """
        Visualise les r√©sultats d'une √©tape sp√©cifique.

        Args:
            model: Mod√®le NCA entra√Æn√©
            stage_nb: Num√©ro d'√©tape √† visualiser
        Returns:
            Dictionnaire avec les donn√©es de visualisation
        """
        print(f"\nüé® G√©n√©ration des visualisations pour l'√©tape {stage_nb}...")
        
        # G√©n√©ration de la s√©quence de test avec seed fixe
        torch.manual_seed(CONFIG.VISUALIZATION_SEED)
        np.random.seed(CONFIG.VISUALIZATION_SEED)
        
        target_seq, source_mask, obstacle_mask = simulator.generate_stage_sequence(
                stage_nb=stage_nb,
                n_steps=CONFIG.POSTVIS_STEPS,
                size=CONFIG.GRID_SIZE
        )
        
        # Pr√©diction du mod√®le
        model.eval()
        updater = OptimizedNCAUpdater(model)
        
        # Simulation NCA avec torch.no_grad() pour √©viter le gradient
        nca_sequence = []
        grid_pred = torch.zeros_like(target_seq[0])
        grid_pred[source_mask] = CONFIG.SOURCE_INTENSITY
        nca_sequence.append(grid_pred.clone())
        
        with torch.no_grad():  # D√©sactive le calcul de gradient pour les visualisations
            for _ in range(CONFIG.POSTVIS_STEPS):
                grid_pred = updater.step(grid_pred, source_mask, obstacle_mask)
                nca_sequence.append(grid_pred.clone())
        
        # Cr√©ation des visualisations avec .detach() pour s√©curit√©
        vis_data = {
            'stage_nb':        stage_nb,
            'target_sequence': [t.detach().cpu().numpy() for t in target_seq],
            'nca_sequence':    [t.detach().cpu().numpy() for t in nca_sequence],
            'source_mask':     source_mask.detach().cpu().numpy(),
            'obstacle_mask':   obstacle_mask.detach().cpu().numpy(),
            'vis_seed':        CONFIG.VISUALIZATION_SEED,
        }
        
        # Sauvegarde des animations
        self._create_stage_animations(vis_data)
        self._create_stage_convergence_plot(vis_data)
        
        model.train()
        return
    
    
    def _create_stage_animations(self, vis_data: Dict[str, Any]):
        """Cr√©e les animations GIF pour une √©tape."""
        stage_nb = vis_data['stage_nb']
        stage_dir = Path(CONFIG.OUTPUT_DIR) / f"stage_{stage_nb}"
        stage_dir.mkdir(parents=True, exist_ok=True)
        
        # Animation comparative
        self._save_comparison_gif(
                vis_data['target_sequence'],
                vis_data['nca_sequence'],
                vis_data['obstacle_mask'],
                stage_dir / f"animation_comparaison_√©tape_{stage_nb}.gif",
                f"√âtape {stage_nb} - Comparaison Cible vs NCA"
        )
        
        # Animation NCA seule
        self._save_single_gif(
                vis_data['nca_sequence'],
                vis_data['obstacle_mask'],
                stage_dir / f"animation_nca_√©tape_{stage_nb}.gif",
                f"√âtape {stage_nb} - Pr√©diction NCA"
        )
        
        print(f"‚úÖ Animations √©tape {stage_nb} sauvegard√©es dans {stage_dir}")
    
    
    def _create_stage_convergence_plot(self, vis_data: Dict[str, Any]):
        """Cr√©e le graphique de convergence pour une √©tape."""
        stage_nb = vis_data['stage_nb']
        stage_dir = Path(CONFIG.OUTPUT_DIR) / f"stage_{stage_nb}"
        
        target_seq = vis_data['target_sequence']
        nca_seq = vis_data['nca_sequence']
        
        # Calcul de l'erreur temporelle
        errors = []
        for t in range(min(len(target_seq), len(nca_seq))):
            error = np.mean((target_seq[t] - nca_seq[t]) ** 2)
            errors.append(error)
        
        # Graphique
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(errors, 'b-', linewidth=2, label='Erreur MSE')
        
        ax.set_xlabel('Pas de temps')
        ax.set_ylabel('Erreur MSE')
        ax.set_title(f'Convergence √âtape {stage_nb} - Seed {vis_data["vis_seed"]}')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        convergence_path = stage_dir / f"convergence_√©tape_{stage_nb}.png"
        plt.savefig(convergence_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"‚úÖ Graphique de convergence √©tape {stage_nb} sauvegard√©: {convergence_path}")
    
    
    def _save_comparison_gif(self, target_seq: List[np.ndarray], nca_seq: List[np.ndarray],
                             obstacle_mask: np.ndarray, filepath: Path, title: str):
        """Sauvegarde un GIF de comparaison c√¥te √† c√¥te."""
        import matplotlib.animation as animation
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        
        def animate(frame):
            ax1.clear()
            ax2.clear()
            
            # Cible
            im1 = ax1.imshow(target_seq[frame], cmap='hot', vmin=0, vmax=1)
            ax1.contour(obstacle_mask, levels=[0.5], colors='cyan', linewidths=2)
            ax1.set_title(f'Cible - t={frame}')
            ax1.set_xticks([])
            ax1.set_yticks([])
            
            # NCA
            im2 = ax2.imshow(nca_seq[frame], cmap='hot', vmin=0, vmax=1)
            ax2.contour(obstacle_mask, levels=[0.5], colors='cyan', linewidths=2)
            ax2.set_title(f'NCA - t={frame}')
            ax2.set_xticks([])
            ax2.set_yticks([])
            
            return [im1, im2]
        
        
        n_frames = min(len(target_seq), len(nca_seq))
        ani = animation.FuncAnimation(fig, animate, frames=n_frames, interval=200, blit=False)
        ani.save(filepath, writer='pillow', fps=5)
        plt.close()
    
    
    def _save_single_gif(self, sequence: List[np.ndarray], obstacle_mask: np.ndarray,
                         filepath: Path, title: str):
        """Sauvegarde un GIF d'une s√©quence unique."""
        import matplotlib.animation as animation
        
        fig, ax = plt.subplots(figsize=(8, 8))
        
        
        def animate(frame):
            ax.clear()
            im = ax.imshow(sequence[frame], cmap='hot', vmin=0, vmax=1)
            ax.contour(obstacle_mask, levels=[0.5], colors='cyan', linewidths=2)
            ax.set_title(f'{title} - t={frame}')
            ax.set_xticks([])
            ax.set_yticks([])
            return [im]
        
        
        ani = animation.FuncAnimation(fig, animate, frames=len(sequence), interval=200, blit=False)
        ani.save(filepath, writer='pillow', fps=5)
        plt.close()
    
    
    def create_curriculum_summary(self, global_metrics: Dict[str, Any]):
        """Cr√©e un r√©sum√© visuel complet du curriculum d'apprentissage."""
        print("\nüé® G√©n√©ration du r√©sum√© visuel du curriculum...")
        
        # Graphique de progression globale
        self._plot_curriculum_progression(global_metrics)
        
        # Comparaison inter-√©tapes
        self._plot_stage_comparison(global_metrics)
        
        # M√©triques de performance
        self._plot_performance_metrics(global_metrics)
        
        print("‚úÖ R√©sum√© visuel complet g√©n√©r√©")
    
    
    def _plot_curriculum_progression(self, metrics: Dict[str, Any]):
        """Graphique de la progression globale du curriculum."""
        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(14, 15))
        
        # Historique des pertes avec codes couleur par √©tape
        losses = metrics['global_history']['losses']
        stages = metrics['global_history']['stages']
        epochs = metrics['global_history']['epochs']
        
        stage_colors = {1: 'green', 2: 'orange', 3: 'red'}
        
        for stage_nb in [1, 2, 3]:
            stage_indices = [i for i, s in enumerate(stages) if s == stage_nb]
            stage_losses = [losses[i] for i in stage_indices]
            stage_epochs = [epochs[i] for i in stage_indices]
            
            if stage_losses:
                ax1.plot(stage_epochs, stage_losses,
                         color=stage_colors[stage_nb],
                         label=f'√âtape {stage_nb}',
                         linewidth=2)
        
        ax1.set_xlabel('√âpoque')
        ax1.set_ylabel('Perte MSE')
        ax1.set_title('Progression du Curriculum d\'Apprentissage')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        ax1.set_yscale('log')
        
        # Learning rate par √©tape
        for stage_nb in [1, 2, 3]:
            stage_history = metrics['stage_histories'][stage_nb]
            if stage_history['lr']:
                stage_epochs_local = [metrics['stage_start_epochs'].get(stage_nb, 0) + e
                                      for e in stage_history['epochs']]
                ax2.plot(stage_epochs_local, stage_history['lr'],
                         color=stage_colors[stage_nb],
                         label=f'LR √âtape {stage_nb}',
                         linewidth=2)
        
        ax2.set_xlabel('√âpoque')
        ax2.set_ylabel('Learning Rate')
        ax2.set_title('√âvolution du Learning Rate par √âtape')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.set_yscale('log')
        
        # Acc√©l√©ration du Learning Rate (d√©riv√©e seconde) pour d√©tecter les changements d'acc√©l√©ration
        for stage_nb in [1, 2, 3]:
            stage_history = metrics['stage_histories'][stage_nb]
            if stage_history['lr'] and len(stage_history['lr']) > 2:  # Besoin d'au moins 3 points pour d√©riv√©e seconde
                # Calcul de la d√©riv√©e premi√®re (vitesse)
                lr_values = stage_history['lr']
                lr_velocity = []
                
                for i in range(1, len(lr_values)):
                    velocity = lr_values[i] - lr_values[i - 1]
                    lr_velocity.append(velocity)
                
                # Calcul de la d√©riv√©e seconde (acc√©l√©ration de l'acc√©l√©ration)
                lr_acceleration = []
                for i in range(1, len(lr_velocity)):
                    acceleration = lr_velocity[i] - lr_velocity[i - 1]
                    lr_acceleration.append(acceleration)
                
                # √âpoques correspondantes (on commence √† l'√©poque 2 car on a besoin de 3 points pour la d√©riv√©e seconde)
                stage_epochs_acceleration = [metrics['stage_start_epochs'].get(stage_nb, 0) + e
                                             for e in stage_history['epochs'][2:]]
                
                if lr_acceleration:
                    ax3.plot(stage_epochs_acceleration, lr_acceleration,
                             color=stage_colors[stage_nb],
                             label=f'Acc√©l√©ration LR √âtape {stage_nb}',
                             linewidth=2,
                             marker='o', markersize=3, alpha=0.7)
                    
                    # Ligne de r√©f√©rence √† z√©ro pour identifier les changements d'acc√©l√©ration
                    ax3.axhline(y=0, color='black', linestyle='-', alpha=0.3, linewidth=1)
                    
                    # Zone n√©gative (d√©c√©l√©ration) en rouge transparent
                    negative_mask = [a < 0 for a in lr_acceleration]
                    if any(negative_mask):
                        ax3.fill_between(stage_epochs_acceleration, lr_acceleration, 0,
                                         where=negative_mask,
                                         alpha=0.2, color='red',
                                         label='Zone de d√©c√©l√©ration' if stage_nb == 1 else "")
                    
                    # Zone positive (acc√©l√©ration croissante) en vert transparent
                    positive_mask = [a > 0 for a in lr_acceleration]
                    if any(positive_mask):
                        ax3.fill_between(stage_epochs_acceleration, lr_acceleration, 0,
                                         where=positive_mask,
                                         alpha=0.2, color='green',
                                         label='Zone d\'acc√©l√©ration' if stage_nb == 1 else "")
                    
                    # D√©tection et marquage des points d'inflexion
                    inflection_points_epochs = []
                    inflection_points_values = []
                    
                    for i in range(1, len(lr_acceleration)):
                        # Point d'inflexion = changement de signe dans l'acc√©l√©ration
                        prev_accel = lr_acceleration[i - 1]
                        curr_accel = lr_acceleration[i]
                        
                        # V√©rifier si on traverse z√©ro (changement de signe)
                        if (prev_accel > 0 and curr_accel < 0) or (prev_accel < 0 and curr_accel > 0):
                            # Filtre tr√®s l√©ger pour √©viter seulement le bruit extr√™me
                            if abs(prev_accel) > 1e-12 or abs(curr_accel) > 1e-12:
                                inflection_epoch = stage_epochs_acceleration[i]
                                inflection_value = curr_accel
                                inflection_points_epochs.append(inflection_epoch)
                                inflection_points_values.append(inflection_value)
                    
                    # Marquer les points d'inflexion sur le graphique
                    if inflection_points_epochs:
                        ax3.scatter(inflection_points_epochs, inflection_points_values,
                                    color=stage_colors[stage_nb],
                                    s=80, marker='X',
                                    edgecolors='black', linewidth=2,
                                    label=f'Points d\'inflexion √âtape {stage_nb}' if stage_nb == 1 else "",
                                    zorder=5, alpha=0.9)
                        
                        # Annotations pour les points d'inflexion les plus significatifs
                        for i, (epoch, value) in enumerate(zip(inflection_points_epochs, inflection_points_values)):
                            if i < 3:  # Limite √† 3 annotations par √©tape pour √©viter l'encombrement
                                ax3.annotate(f'Inflexion\n√â{epoch}',
                                             xy=(epoch, value),
                                             xytext=(10, 20 if value > 0 else -30),
                                             textcoords='offset points',
                                             fontsize=8,
                                             color=stage_colors[stage_nb],
                                             bbox=dict(boxstyle='round,pad=0.3',
                                                       facecolor='white',
                                                       edgecolor=stage_colors[stage_nb],
                                                       alpha=0.8),
                                             arrowprops=dict(arrowstyle='->',
                                                             connectionstyle='arc3,rad=0.2',
                                                             color=stage_colors[stage_nb],
                                                             alpha=0.7))
        
        ax3.set_xlabel('√âpoque')
        ax3.set_ylabel('Acc√©l√©ration LR (Œî¬≤LR par √©poque¬≤)')
        ax3.set_title('Acc√©l√©ration du Learning Rate - Points d\'Inflexion et Changements d\'Acc√©l√©ration')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # Annotation explicative pour interpr√©ter le graphique d'acc√©l√©ration avec points d'inflexion
        ax3.text(0.02, 0.98,
                 'Valeurs n√©gatives = LR d√©c√©l√®re (ralentissement qui s\'acc√©l√®re)\n'
                 'Valeurs positives = LR acc√©l√®re (acc√©l√©ration qui s\'intensifie)\n'
                 'Valeurs proches de 0 = Vitesse LR constante (acc√©l√©ration stable)\n'
                 'X = Points d\'inflexion (changements de dynamique du LR)\n'
                 'Les points d\'inflexion indiquent des changements de politique d\'optimisation',
                 transform=ax3.transAxes,
                 fontsize=9,
                 verticalalignment='top',
                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        plt.tight_layout()
        plt.savefig(Path(CONFIG.OUTPUT_DIR) / "curriculum_progression.png",
                    dpi=150, bbox_inches='tight')
        plt.close()
    
    
    def _plot_stage_comparison(self, metrics: Dict[str, Any]):
        """Graphique de comparaison entre √©tapes."""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        stages = [1, 2, 3]
        stage_names = ["Sans obstacles", "Un obstacle", "Obstacles multiples"]
        
        ax1.set_ylabel('Perte finale')
        ax1.set_title('Perte Finale par √âtape')
        ax1.set_yscale('log')
        
        # √âpoques utilis√©es par √©tape
        epochs_used = [metrics['stage_metrics'][s]['epochs_trained'] for s in stages]
        epochs_planned = [CONFIG.STAGE_1_EPOCHS, CONFIG.STAGE_2_EPOCHS, CONFIG.STAGE_3_EPOCHS]
        
        x = np.arange(len(stages))
        width = 0.35
        
        ax2.bar(x - width / 2, epochs_planned, width, label='Pr√©vues', alpha=0.7, color='lightblue')
        ax2.bar(x + width / 2, epochs_used, width, label='Utilis√©es', alpha=0.7, color='darkblue')
        
        ax2.set_xlabel('√âtape')
        ax2.set_ylabel('Nombre d\'√©poques')
        ax2.set_title('√âpoques Pr√©vues vs Utilis√©es')
        ax2.set_xticks(x)
        ax2.set_xticklabels(stage_names, rotation=15)
        ax2.legend()
        
        # Temps de convergence
        convergence_times = []
        for stage_nb in stages:
            stage_losses = metrics['stage_metrics'][stage_nb]['loss_history']
            convergence_times.append(len(stage_losses))
        
        ax3.plot(stages, convergence_times, 'o-', linewidth=2, markersize=8, color='purple')
        ax3.set_xlabel('√âtape')
        ax3.set_ylabel('√âpoque de convergence')
        ax3.set_title('Vitesse de Convergence par √âtape')
        ax3.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(Path(CONFIG.OUTPUT_DIR) / "stage_comparison.png",
                    dpi=150, bbox_inches='tight')
        plt.close()
    
    
    def _plot_performance_metrics(self, metrics: Dict[str, Any]):
        """Graphique des m√©triques de performance globales."""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # R√©sum√© textuel des performances
        total_time = metrics['total_time_seconds']
        total_epochs = metrics['total_epochs_actual']
        final_loss = metrics['final_loss']
        
        summary_text = f"""
üéØ R√âSUM√â ENTRA√éNEMENT MODULAIRE NCA

üìä STATISTIQUES GLOBALES:
   ‚Ä¢ Seed: {CONFIG.SEED}
   ‚Ä¢ Temps total: {total_time / 60:.1f} minutes ({total_time:.1f}s)
   ‚Ä¢ √âpoques totales: {total_epochs}
   ‚Ä¢ Perte finale: {final_loss:.6f}

üèÜ PERFORMANCE PAR √âTAPE:"""
        
        for stage_nb in [1, 2, 3]:
            stage_data = metrics['stage_metrics'][stage_nb]
            stage_name = {1: "Sans obstacles", 2: "Un obstacle", 3: "Obstacles multiples"}[stage_nb]
            
            summary_text += f"""
   ‚Ä¢ √âtape {stage_nb} ({stage_name}):
     - √âpoques: {stage_data['epochs_trained']}
     - Perte finale: {stage_data['final_loss']:.6f}
     - Arr√™t pr√©coce: {'‚úÖ' if stage_data['early_stopped'] else '‚ùå'}"""
        
        summary_text += f"""

üìà ARCHITECTURE:
   ‚Ä¢ Taille grille: {CONFIG.GRID_SIZE}x{CONFIG.GRID_SIZE}
   ‚Ä¢ Couches cach√©es: {CONFIG.HIDDEN_SIZE} neurones, {CONFIG.N_LAYERS} couches
   ‚Ä¢ Pas temporels NCA: {CONFIG.NCA_STEPS}
   ‚Ä¢ Taille batch: {CONFIG.BATCH_SIZE}
        """
        
        ax.text(0.05, 0.95, summary_text, transform=ax.transAxes,
                fontsize=10, verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        
        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1)
        ax.axis('off')
        ax.set_title('R√©sum√© Performance Entra√Ænement Modulaire NCA', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(Path(CONFIG.OUTPUT_DIR) / "performance_summary.png", dpi=150, bbox_inches='tight')
        plt.close()
