import json
from abc import ABC
from pathlib import Path
from typing import Tuple, List

import torch
from config import CONFIG
from simulation_temporal_sequence import SimulationTemporalSequence
from torch.nn import functional as F

from reality_world import RealityWorld


class BaseStage(ABC):
    NAME = 'UNSET'
    DISPLAY_NAME = 'Ã‰tape non dÃ©finie'
    
    COLOR = 'black'
    
    
    def __init__(self):
        self._stage_nb = -1  # NumÃ©ro de l'Ã©tape, Ã  dÃ©finir dans les sous-classes
        
        # Metrics
        self._metrics_epochs_trained = 0
        self._metrics_loss_history = []
        self._metrics_stage_lrs = []
        
        # CACHE
        self._reality_sequences_for_training = []  # type: List[SimulationTemporalSequence]
        self._reality_sequences_for_training_current_indices = 0
        
        # step player
        self._kernel_avg_3x3 = torch.ones((1, 1, 3, 3), device=CONFIG.DEVICE) / 9.0  # Average 3x3
    
    
    def get_name(self):
        return self.NAME
    
    
    def get_display_name(self):
        return self.DISPLAY_NAME
    
    
    def get_color(self):
        return self.COLOR
    
    
    def set_stage_nb(self, stage_nb: int):
        self._stage_nb = stage_nb
    
    
    def set_metrics(self, epochs_trained: int, loss_history: list, stage_lrs: list):
        self._metrics_epochs_trained = epochs_trained
        self._metrics_loss_history = loss_history
        self._metrics_stage_lrs = stage_lrs
    
    
    def get_stage_nb(self):
        return self._stage_nb
    
    
    def generate_obstacles(self, size: int, source_pos: Tuple[int, int]) -> torch.Tensor:
        """
                GÃ©nÃ¨re un environnement d'obstacles adaptÃ© Ã  l'Ã©tape courante.

                Args:
                    size: Taille de la grille
                    source_pos: Position de la source (i, j)

                Returns:
                    Masque des obstacles [H, W]
                """
        raise NotImplementedError("Subclasses should implement this method.")
    
    
    def _get_stage_dir(self):
        # type: () -> Path
        stage_dir = Path(CONFIG.OUTPUT_DIR) / f"stage_{self.get_stage_nb()}"
        stage_dir.mkdir(parents=True, exist_ok=True)
        return stage_dir
    
    
    def get_metrics(self):
        """Retourne les mÃ©triques de l'Ã©tape."""
        
        return {
            'stage_nb':       self.get_stage_nb(),
            'epochs_trained': self._metrics_epochs_trained,
            'loss_history':   self._metrics_loss_history,
        }
    
    
    def get_loss_history(self):
        return self._metrics_loss_history
    
    
    def get_metrics_epochs_trained(self):
        return self._metrics_epochs_trained
    
    
    def get_metrics_lrs(self):
        return self._metrics_stage_lrs
    
    
    def save_stage_checkpoint(self, model_state_dict, optimizer_state_dict):
        # Type: (Dict, Dict) -> None
        """Sauvegarde le checkpoint d'une Ã©tape."""
        
        stage_dir = self._get_stage_dir()
        
        metrics = self.get_metrics()
        
        # Sauvegarde du modÃ¨le
        model_path = stage_dir / "model_checkpoint.pth"
        torch.save({
            'model_state_dict':     model_state_dict,
            'optimizer_state_dict': optimizer_state_dict,
            'stage_nb':             self.get_stage_nb(),
            'metrics':              metrics,
            'config':               CONFIG.__dict__
        }, model_path)
        
        # Sauvegarde des mÃ©triques en JSON
        metrics_path = stage_dir / "metrics.json"
        with open(metrics_path, 'w') as f:
            json.dump(metrics, f, indent=2, default=str)
        
        print(f"ðŸ’¾ Checkpoint Ã©tape {self.get_stage_nb()} sauvegardÃ©: {stage_dir}")
    
    
    def get_sequences_for_training(self):
        # type: (BaseStage) -> SimulationTemporalSequence
        """RÃ©cupÃ¨re un Ã©chantillon pour l'Ã©tape spÃ©cifiÃ©e."""
        stage_nb = self.get_stage_nb()
        if not self._reality_sequences_for_training:
            raise Exception("Le cache de sÃ©quences n'a pas Ã©tÃ© gÃ©nÃ©rÃ© pour l'Ã©tape {stage_nb}.")
        
        # RÃ©cupÃ¨re l'Ã©chantillon courant et avance l'index
        sequence = self._reality_sequences_for_training[self._reality_sequences_for_training_current_indices]  # type: SimulationTemporalSequence
        self._reality_sequences_for_training_current_indices = (self._reality_sequences_for_training_current_indices + 1) % len(
                self._reality_sequences_for_training)
        
        return sequence
    
    
    def generate_reality_sequences_for_training(self):
        cache_size = CONFIG.STAGE_CACHE_SIZE
        print(f"ðŸŽ¯ GÃ©nÃ©ration de {cache_size} sÃ©quences pour l'Ã©tape {self.get_stage_nb()}...", end='', flush=True)
        
        # sequences = []  # :Type: List[Sequence]
        for i in range(cache_size):
            if i % 50 == 0:
                print(f"\r   Ã‰tape {self.get_stage_nb()}: {i}/{cache_size}                                 ", end='', flush=True)
            
            target_sequence = self.generate_simulation_sequence(n_steps=CONFIG.NCA_STEPS, size=CONFIG.GRID_SIZE)
            
            self._reality_sequences_for_training.append(target_sequence)
        
        print(f"\râœ… Cache Ã©tape {self.get_stage_nb()} crÃ©Ã© ({cache_size} sÃ©quences)")
    
    
    def generate_simulation_sequence(self, n_steps, size):
        # type: (int, int) -> SimulationTemporalSequence
        """
        GÃ©nÃ¨re une sÃ©quence adaptÃ©e Ã  l'Ã©tape d'apprentissage courante.

        Args:
            n_steps: Nombre d'Ã©tapes de simulation
            size: Taille de la grille

        Returns :
            (sÃ©quence, masque_source, masque_obstacles)
        """
        # Position alÃ©atoire de la source
        g = torch.Generator(device=CONFIG.DEVICE)
        g.manual_seed(CONFIG.SEED)
        i0 = torch.randint(2, size - 2, (1,), generator=g, device=CONFIG.DEVICE).item()
        j0 = torch.randint(2, size - 2, (1,), generator=g, device=CONFIG.DEVICE).item()
        
        # GÃ©nÃ©ration d'obstacles selon l'Ã©tape
        obstacle_mask = self.generate_obstacles(size, (i0, j0))
        
        # Initialisation
        grid = torch.zeros((size, size), device=CONFIG.DEVICE)
        grid[i0, j0] = CONFIG.SOURCE_INTENSITY
        
        source_mask = torch.zeros_like(grid, dtype=torch.bool)
        source_mask[i0, j0] = True
        
        # S'assurer que la source n'est pas dans un obstacle
        if obstacle_mask[i0, j0]:
            obstacle_mask[i0, j0] = False
        
        # Simulation temporelle
        reality_worlds = [RealityWorld(grid.clone())]
        for _ in range(n_steps):
            grid = self._play_diffusion_step(grid, source_mask, obstacle_mask)
            reality_worlds.append(RealityWorld(grid.clone()))
        
        sequence = SimulationTemporalSequence(reality_worlds, source_mask, obstacle_mask)
        return sequence
    
    
    # Un pas de diffusion de chaleur avec obstacles
    def _play_diffusion_step(self, grid, source_mask, obstacle_mask):
        # type: (torch.Tensor, torch.Tensor, torch.Tensor) -> torch.Tensor
        
        x = grid.unsqueeze(0).unsqueeze(0)
        new_grid = F.conv2d(x, self._kernel_avg_3x3, padding=1).squeeze(0).squeeze(0)
        
        new_grid[obstacle_mask] = 0.0  # No diffusion on obstacles
        new_grid[source_mask] = grid[source_mask]  # Keep source intensity
        
        return new_grid
