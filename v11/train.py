import json
import os
# HACK for imports
import sys
import time
from pathlib import Path
from typing import Tuple, List, Dict, Any

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim



# Hack for imports
sys.path.append(os.path.dirname(__file__))

from config import CONFIG
from torching import DEVICE

# =============================================================================
# Configuration et initialisation modulaire
# =============================================================================


SEED = CONFIG.SEED
VISUALIZATION_SEED = CONFIG.VISUALIZATION_SEED
STAGNATION_THRESHOLD = CONFIG.STAGNATION_THRESHOLD
STAGNATION_PATIENCE = CONFIG.STAGNATION_PATIENCE

# Initialisation
torch.manual_seed(SEED)
np.random.seed(SEED)

# Cr√©ation du r√©pertoire de sortie avec seed
CONFIG.OUTPUT_DIR = f"outputs"
os.makedirs(CONFIG.OUTPUT_DIR, exist_ok=True)

print(f"Device: {DEVICE}")
print(f"Seed: {SEED}")
print(f"R√©pertoire de sortie: {CONFIG.OUTPUT_DIR}")

from stage_manager import STAGE_MANAGER


# =============================================================================
# Gestionnaire d'obstacles progressifs
# =============================================================================

class ProgressiveObstacleManager:
    """
    Gestionnaire intelligent des obstacles selon l'√©tape d'apprentissage.
    G√©n√®re des environnements appropri√©s pour chaque phase du curriculum.
    """
    
    
    def __init__(self):
        pass
    
    
    def generate_stage_environment(self, stage_nb: int, size: int, source_pos: Tuple[int, int]) -> torch.Tensor:
        """
        G√©n√®re un environnement d'obstacles adapt√© √† l'√©tape courante.
        
        Args:
            stage_nb: Num√©ro d'√©tape (1, 2, ou 3)
            size: Taille de la grille
            source_pos: Position de la source (i, j)
            
        Returns:
            Masque des obstacles [H, W]
        """
        
        stage = STAGE_MANAGER.get_stage(stage_nb)
        # print(f"üéØ G√©n√©ration d'environnement pour l'√©tape {stage_nb} ({stage.get_name()})...")
        
        return stage.generate_environment(size, source_pos)
        # if stage_nb == 1:
        #     return self._generate_stage_1_environment(size)
        # elif stage_nb == 2:
        #     return self._generate_stage_2_environment(size, source_pos)
        # elif stage_nb == 3:
        #     return self._generate_stage_3_environment(size, source_pos)
    
    
    # def _generate_stage_1_environment(self, size: int) -> torch.Tensor:
    #     """√âtape 1: Aucun obstacle - grille vide pour apprentissage de base."""
    #     return torch.zeros((size, size), dtype=torch.bool, device=DEVICE)
    
    # def _generate_stage_2_environment(self, size: int, source_pos: Tuple[int, int]) -> torch.Tensor:
    #     """√âtape 2: Un seul obstacle pour apprentissage du contournement."""
    #     obstacle_mask = torch.zeros((size, size), dtype=torch.bool, device=DEVICE)
    #
    #     g = torch.Generator(device=DEVICE)
    #     g.manual_seed(SEED)
    #
    #     # Un seul obstacle de taille al√©atoire
    #     obstacle_size = torch.randint(CONFIG.MIN_OBSTACLE_SIZE, CONFIG.MAX_OBSTACLE_SIZE + 1,
    #                                   (1,), generator=g, device=DEVICE).item()
    #
    #     # Placement en √©vitant la source et les bords
    #     max_pos = size - obstacle_size
    #     if max_pos <= 1:
    #         return obstacle_mask  # Grille trop petite
    #
    #     source_i, source_j = source_pos
    #
    #     for attempt in range(100):  # Plus de tentatives pour √©tape 2
    #         i = torch.randint(1, max_pos, (1,), generator=g, device=DEVICE).item()
    #         j = torch.randint(1, max_pos, (1,), generator=g, device=DEVICE).item()
    #
    #         # V√©rifier non-chevauchement avec source
    #         if not (i <= source_i < i + obstacle_size and j <= source_j < j + obstacle_size):
    #             obstacle_mask[i:i + obstacle_size, j:j + obstacle_size] = True
    #             break
    #
    #     return obstacle_mask
    
    # def _generate_stage_3_environment(self, size: int, source_pos: Tuple[int, int]) -> torch.Tensor:
    #     """√âtape 3: Obstacles multiples pour gestion de la complexit√©."""
    #     obstacle_mask = torch.zeros((size, size), dtype=torch.bool, device=DEVICE)
    #
    #     g = torch.Generator(device=DEVICE)
    #     g.manual_seed(SEED)
    #
    #     config = self.stage_configs[3]
    #     n_obstacles = torch.randint(config['min_obstacles'], config['max_obstacles'] + 1,
    #                                 (1,), generator=g, device=DEVICE).item()
    #
    #     source_i, source_j = source_pos
    #     placed_obstacles = []
    #
    #     for obstacle_idx in range(n_obstacles):
    #         obstacle_size = torch.randint(CONFIG.MIN_OBSTACLE_SIZE, CONFIG.MAX_OBSTACLE_SIZE + 1,
    #                                       (1,), generator=g, device=DEVICE).item()
    #
    #         max_pos = size - obstacle_size
    #         if max_pos <= 1:
    #             continue
    #
    #         for attempt in range(50):
    #             i = torch.randint(1, max_pos, (1,), generator=g, device=DEVICE).item()
    #             j = torch.randint(1, max_pos, (1,), generator=g, device=DEVICE).item()
    #
    #             # V√©rifications multiples pour √©tape 3
    #             valid_position = True
    #
    #             # 1. Pas de chevauchement avec source
    #             if i <= source_i < i + obstacle_size and j <= source_j < j + obstacle_size:
    #                 valid_position = False
    #
    #             # 2. Pas de chevauchement avec obstacles existants
    #             for obs_i, obs_j, obs_size in placed_obstacles:
    #                 if (i < obs_i + obs_size and i + obstacle_size > obs_i and
    #                         j < obs_j + obs_size and j + obstacle_size > obs_j):
    #                     valid_position = False
    #                     break
    #
    #             if valid_position:
    #                 obstacle_mask[i:i + obstacle_size, j:j + obstacle_size] = True
    #                 placed_obstacles.append((i, j, obstacle_size))
    #                 break
    #
    #     # Validation finale de connectivit√©
    #     if not self._validate_connectivity(obstacle_mask, source_pos):
    #         print("‚ö†Ô∏è  Connectivit√© non garantie - g√©n√©ration d'un environnement plus simple")
    #         return self._generate_stage_2_environment(size, source_pos)
    #
    #     return obstacle_mask
    
    # def _validate_connectivity(self, obstacle_mask: torch.Tensor, source_pos: Tuple[int, int]) -> bool:
    #     """
    #     Valide qu'un chemin de diffusion reste possible avec les obstacles.
    #     Utilise un algorithme de flood-fill simplifi√©.
    #     """
    #     H, W = obstacle_mask.shape
    #     source_i, source_j = source_pos
    #
    #     # Matrice de visite
    #     visited = torch.zeros_like(obstacle_mask, dtype=torch.bool)
    #     visited[obstacle_mask] = True  # Les obstacles sont "d√©j√† visit√©s"
    #
    #     # Flood-fill depuis la source
    #     stack = [(source_i, source_j)]
    #     visited[source_i, source_j] = True
    #     accessible_cells = 1
    #
    #     while stack:
    #         i, j = stack.pop()
    #
    #         # Parcours des 4 voisins
    #         for di, dj in [(-1, 0), (1, 0), (0, -1), (0, 1)]:
    #             ni, nj = i + di, j + dj
    #
    #             if (0 <= ni < H and 0 <= nj < W and
    #                     not visited[ni, nj] and not obstacle_mask[ni, nj]):
    #                 visited[ni, nj] = True
    #                 stack.append((ni, nj))
    #                 accessible_cells += 1
    #
    #     # Au moins 50% de la grille doit √™tre accessible pour une bonne diffusion
    #     total_free_cells = (H * W) - obstacle_mask.sum().item()
    #     connectivity_ratio = accessible_cells / max(total_free_cells, 1)
    #
    #     return connectivity_ratio >= 0.5
    
    def get_difficulty_metrics(self, stage_nb: int, obstacle_mask: torch.Tensor) -> Dict[str, float]:
        """
        Calcule des m√©triques de difficult√© pour l'environnement g√©n√©r√©.
        
        Returns:
            Dictionnaire avec les m√©triques de complexit√©
        """
        H, W = obstacle_mask.shape
        total_cells = H * W
        obstacle_cells = obstacle_mask.sum().item()
        
        metrics = {
            'stage_nb':         stage_nb,
            'obstacle_ratio':   obstacle_cells / total_cells,
            'free_cells':       total_cells - obstacle_cells,
            'complexity_score': stage_nb * (obstacle_cells / total_cells)
        }
        
        return metrics


# =============================================================================
# Simulateur de diffusion
# =============================================================================

class DiffusionSimulator:
    """
    Simulateur de diffusion de chaleur adapt√© pour l'apprentissage modulaire.
    Utilise le gestionnaire d'obstacles progressifs.
    """
    
    
    def __init__(self):
        self.kernel = torch.ones((1, 1, 3, 3), device=DEVICE) / 9.0
        self.obstacle_manager = ProgressiveObstacleManager()
    
    
    def step(self, grid: torch.Tensor, source_mask: torch.Tensor, obstacle_mask: torch.Tensor) -> torch.Tensor:
        """Un pas de diffusion de chaleur avec obstacles."""
        x = grid.unsqueeze(0).unsqueeze(0)
        new_grid = F.conv2d(x, self.kernel, padding=1).squeeze(0).squeeze(0)
        
        # Contraintes
        new_grid[obstacle_mask] = 0.0
        new_grid[source_mask] = grid[source_mask]
        
        return new_grid
    
    
    def generate_stage_sequence(self, stage_nb: int, n_steps: int, size: int) -> Tuple[List[torch.Tensor], torch.Tensor, torch.Tensor]:
        """
        G√©n√®re une s√©quence adapt√©e √† l'√©tape d'apprentissage courante.
        
        Args:
            stage_nb: √âtape d'apprentissage (1, 2, ou 3)
            n_steps: Nombre d'√©tapes de simulation
            size: Taille de la grille
            
        Returns:
            (s√©quence, masque_source, masque_obstacles)
        """
        # Position al√©atoire de la source
        g = torch.Generator(device=DEVICE)
        g.manual_seed(SEED)
        i0 = torch.randint(2, size - 2, (1,), generator=g, device=DEVICE).item()
        j0 = torch.randint(2, size - 2, (1,), generator=g, device=DEVICE).item()
        
        # G√©n√©ration d'obstacles selon l'√©tape
        obstacle_mask = self.obstacle_manager.generate_stage_environment(stage_nb, size, (i0, j0))
        
        # Initialisation
        grid = torch.zeros((size, size), device=DEVICE)
        grid[i0, j0] = CONFIG.SOURCE_INTENSITY
        
        source_mask = torch.zeros_like(grid, dtype=torch.bool)
        source_mask[i0, j0] = True
        
        # S'assurer que la source n'est pas dans un obstacle
        if obstacle_mask[i0, j0]:
            obstacle_mask[i0, j0] = False
        
        # Simulation temporelle
        sequence = [grid.clone()]
        for _ in range(n_steps):
            grid = self.step(grid, source_mask, obstacle_mask)
            sequence.append(grid.clone())
        
        return sequence, source_mask, obstacle_mask


# Instance globale du simulateur modulaire
simulator = DiffusionSimulator()


# =============================================================================
# Mod√®le NCA
# =============================================================================

class ImprovedNCA(nn.Module):
    """
    Neural Cellular Automaton optimis√© pour l'apprentissage modulaire.
    Architecture identique √† v6 mais avec support √©tendu pour le curriculum.
    """
    
    
    def __init__(self, input_size: int):
        super().__init__()
        
        self.input_size = input_size
        self.hidden_size = CONFIG.HIDDEN_SIZE
        self.n_layers = CONFIG.N_LAYERS
        
        # Architecture profonde avec normalisation
        layers = []
        current_size = input_size
        
        for i in range(self.n_layers):
            layers.append(nn.Linear(current_size, self.hidden_size))
            layers.append(nn.BatchNorm1d(self.hidden_size))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(0.1))
            current_size = self.hidden_size
        
        # Couche de sortie stabilis√©e
        layers.append(nn.Linear(self.hidden_size, 1))
        layers.append(nn.Tanh())
        
        self.network = nn.Sequential(*layers)
        self.delta_scale = 0.1
    
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward pass avec scaling des deltas."""
        delta = self.network(x)
        return delta * self.delta_scale


# =============================================================================
# Updaters NCA
# =============================================================================

class OptimizedNCAUpdater:
    """
    Updater optimis√© avec extraction vectoris√©e des patches.
    """
    
    
    def __init__(self, model: ImprovedNCA):
        self.model = model
    
    
    def step(self, grid: torch.Tensor, source_mask: torch.Tensor, obstacle_mask: torch.Tensor) -> torch.Tensor:
        """Application optimis√©e du NCA."""
        H, W = grid.shape
        
        # Extraction vectoris√©e des patches 3x3
        grid_padded = F.pad(grid.unsqueeze(0).unsqueeze(0), (1, 1, 1, 1), mode='replicate')
        patches = F.unfold(grid_padded, kernel_size=3, stride=1)
        patches = patches.squeeze(0).transpose(0, 1)  # [H*W, 9]
        
        # Features additionnelles
        source_flat = source_mask.flatten().float().unsqueeze(1)  # [H*W, 1]
        obstacle_flat = obstacle_mask.flatten().float().unsqueeze(1)  # [H*W, 1]
        full_patches = torch.cat([patches, source_flat, obstacle_flat], dim=1)  # [H*W, 11]
        
        # Application seulement sur positions valides
        valid_mask = ~obstacle_mask.flatten()
        
        if valid_mask.any():
            valid_patches = full_patches[valid_mask]
            deltas = self.model(valid_patches)
            
            new_grid = grid.clone().flatten()
            new_grid[valid_mask] += deltas.squeeze()
            new_grid = torch.clamp(new_grid, 0.0, 1.0).reshape(H, W)
        else:
            new_grid = grid.clone()
        
        # Contraintes finales
        new_grid[obstacle_mask] = 0.0
        new_grid[source_mask] = grid[source_mask]
        
        return new_grid




# =============================================================================
# Planificateur de curriculum (NOUVEAU)
# =============================================================================


# =============================================================================
# Cache de s√©quences optimis√© par √©tape
# =============================================================================

class OptimizedSequenceCache:
    """
    Cache sp√©cialis√© par √©tape pour l'entra√Ænement modulaire.
    Maintient des caches s√©par√©s pour chaque √©tape d'apprentissage.
    """
    
    
    def __init__(self, simulator: DiffusionSimulator):
        self.simulator = simulator
        self.stage_caches = {}  # Cache par √©tape
        self.cache_sizes = {1: 150, 2: 200, 3: 250}  # Plus de vari√©t√© pour √©tapes complexes
        self.current_indices = {}
    
    
    def initialize_stage_cache(self, stage_nb: int):
        """Initialise le cache pour une √©tape sp√©cifique."""
        if stage_nb in self.stage_caches:
            return  # D√©j√† initialis√©
        
        cache_size = self.cache_sizes.get(stage_nb, 200)
        print(f"üéØ G√©n√©ration de {cache_size} s√©quences pour l'√©tape {stage_nb}...")
        
        sequences = []
        for i in range(cache_size):
            if i % 50 == 0:
                print(f"   √âtape {stage_nb}: {i}/{cache_size}")
            
            target_seq, source_mask, obstacle_mask = self.simulator.generate_stage_sequence(
                    stage_nb=stage_nb,
                    n_steps=CONFIG.NCA_STEPS,
                    size=CONFIG.GRID_SIZE
            )
            
            sequences.append({
                'target_seq':    target_seq,
                'source_mask':   source_mask,
                'obstacle_mask': obstacle_mask,
                'stage_nb':      stage_nb
            })
        
        self.stage_caches[stage_nb] = sequences
        self.current_indices[stage_nb] = 0
        print(f"‚úÖ Cache √©tape {stage_nb} cr√©√© ({cache_size} s√©quences)")
    
    
    def get_stage_batch(self, stage_nb: int, batch_size: int):
        """R√©cup√®re un batch pour l'√©tape sp√©cifi√©e."""
        if stage_nb not in self.stage_caches:
            self.initialize_stage_cache(stage_nb)
        
        cache = self.stage_caches[stage_nb]
        batch = []
        
        for _ in range(batch_size):
            batch.append(cache[self.current_indices[stage_nb]])
            self.current_indices[stage_nb] = (self.current_indices[stage_nb] + 1) % len(cache)
        
        return batch
    
    
    def shuffle_stage_cache(self, stage_nb: int):
        """M√©lange le cache d'une √©tape sp√©cifique."""
        if stage_nb in self.stage_caches:
            import random
            random.shuffle(self.stage_caches[stage_nb])
    
    
    def clear_stage_cache(self, stage_nb: int):
        """Lib√®re la m√©moire du cache d'une √©tape."""
        if stage_nb in self.stage_caches:
            del self.stage_caches[stage_nb]
            del self.current_indices[stage_nb]
            print(f"üóëÔ∏è  Cache √©tape {stage_nb} lib√©r√©")


# =============================================================================
# Entra√Æneur modulaire principal
# =============================================================================

class ModularTrainer:
    """
    Syst√®me d'entra√Ænement modulaire progressif.
    G√®re l'apprentissage par √©tapes avec transitions automatiques.
    """
    
    
    def __init__(self, model: ImprovedNCA):
        self.model = model
        
        # Choix de l'updater optimis√©
        print("üöÄ Utilisation de l'updater optimis√© vectoris√©")
        self.updater = OptimizedNCAUpdater(model)
        
        # Optimiseur et planificateur
        self.optimizer = optim.AdamW(model.parameters(), lr=CONFIG.LEARNING_RATE, weight_decay=1e-4)
        self.loss_fn = nn.MSELoss()
        
        # Curriculum et m√©triques
        from scheduler import CurriculumScheduler
        self.curriculum = CurriculumScheduler()
        
        # Cache optimis√© par √©tape
        self.sequence_cache = OptimizedSequenceCache(simulator)
        self.use_cache = True
        
        # √âtat d'entra√Ænement
        self.current_stage = 1
        self.stage_histories = {stage_nb: {'losses': [], 'epochs': [], 'lr': []} for stage_nb in [1, 2, 3]}
        self.global_history = {'losses': [], 'stages': [], 'epochs': []}
        self.stage_start_epochs = {}
        self.total_epochs_trained = 0
    
    
    def train_step(self, target_sequence: List[torch.Tensor], source_mask: torch.Tensor,
                   obstacle_mask: torch.Tensor, stage_nb: int) -> float:
        """
        Un pas d'entra√Ænement adapt√© √† l'√©tape courante.

        Args:
            target_sequence: S√©quence cible
            source_mask: Masque des sources
            obstacle_mask: Masque des obstacles
            stage_nb: √âtape courante d'entra√Ænement

        Returns:
            Perte pour ce pas
        """
        self.optimizer.zero_grad()
        
        # Initialisation
        grid_pred = torch.zeros_like(target_sequence[0])
        grid_pred[source_mask] = CONFIG.SOURCE_INTENSITY
        
        total_loss = torch.tensor(0.0, device=DEVICE)
        
        # D√©roulement temporel
        for t_step in range(CONFIG.NCA_STEPS):
            target = target_sequence[t_step + 1]
            grid_pred = self.updater.step(grid_pred, source_mask, obstacle_mask)
            
            # Perte pond√©r√©e selon l'√©tape
            step_loss = self.loss_fn(grid_pred, target)
            
            total_loss = total_loss + step_loss
        
        avg_loss = total_loss / CONFIG.NCA_STEPS
        
        # Backpropagation avec clipping
        avg_loss.backward()
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
        
        self.optimizer.step()
        return avg_loss.item()
    
    
    def train_stage(self, stage_nb: int, max_epochs: int) -> Dict[str, Any]:
        """
        Entra√Ænement complet d'une √©tape sp√©cifique.

        Args:
            stage_nb: Num√©ro d'√©tape (1, 2, ou 3)
            max_epochs: Nombre maximum d'√©poques pour cette √©tape

        Returns:
            Dictionnaire avec les m√©triques de l'√©tape
        """
        print(f"\nüéØ === √âTAPE {stage_nb} - D√âBUT ===")
        stage_name = {1: "Sans obstacles", 2: "Un obstacle", 3: "Obstacles multiples"}[stage_nb]
        print(f"üìã {stage_name}")
        print(f"‚è±Ô∏è  Maximum {max_epochs} √©poques")
        
        self.current_stage = stage_nb
        self.stage_start_epochs[stage_nb] = self.total_epochs_trained
        
        # Initialisation du cache pour cette √©tape
        if self.use_cache:
            self.sequence_cache.initialize_stage_cache(stage_nb)
        
        # M√©triques de l'√©tape
        stage_losses = []
        epoch_in_stage = 0
        early_stop = False
        
        # Boucle d'entra√Ænement de l'√©tape
        for epoch_in_stage in range(max_epochs):
            epoch_losses = []
            
            # Ajustement du learning rate si curriculum activ√©
            if self.curriculum:
                self.curriculum.adjust_learning_rate(self.optimizer, stage_nb, epoch_in_stage)
            
            # M√©lange p√©riodique du cache
            if self.use_cache and epoch_in_stage % 20 == 0:
                self.sequence_cache.shuffle_stage_cache(stage_nb)
            
            # Entra√Ænement par batch
            for _ in range(CONFIG.BATCH_SIZE):
                batch_sequences = self.sequence_cache.get_stage_batch(stage_nb, 1)
                seq_data = batch_sequences[0]
                target_seq = seq_data['target_seq']
                source_mask = seq_data['source_mask']
                obstacle_mask = seq_data['obstacle_mask']
                
                loss = self.train_step(target_seq, source_mask, obstacle_mask, stage_nb)
                epoch_losses.append(loss)
            
            # Statistiques de l'√©poque
            avg_epoch_loss = np.mean(epoch_losses)
            stage_losses.append(avg_epoch_loss)
            current_lr = self.optimizer.param_groups[0]['lr']
            
            # Historiques
            self.stage_histories[stage_nb]['losses'].append(avg_epoch_loss)
            self.stage_histories[stage_nb]['epochs'].append(epoch_in_stage)
            self.stage_histories[stage_nb]['lr'].append(current_lr)
            
            self.global_history['losses'].append(avg_epoch_loss)
            self.global_history['stages'].append(stage_nb)
            self.global_history['epochs'].append(self.total_epochs_trained)
            
            self.total_epochs_trained += 1
            
            # Affichage p√©riodique
            if epoch_in_stage % 10 == 0 or epoch_in_stage == max_epochs - 1:
                print(f"  √âpoque {epoch_in_stage:3d}/{max_epochs - 1} | "
                      f"Loss: {avg_epoch_loss:.6f} | "
                      f"LR: {current_lr:.2e}")
            
            # V√©rification de l'avancement automatique (curriculum)
            if self.curriculum.should_advance_stage(stage_nb, stage_losses):
                print(f"üéØ Convergence atteinte √† l'√©poque {epoch_in_stage}")
                print(f"   Loss: {avg_epoch_loss:.6f}")
                early_stop = True
                break
        
        # R√©sum√© de l'√©tape
        final_loss = stage_losses[-1] if stage_losses else float('inf')
        # convergence_met = final_loss < CONFIG.CONVERGENCE_THRESHOLDS.get(stage_nb, 0.05)
        
        stage_metrics = {
            'stage_nb':       stage_nb,
            'epochs_trained': epoch_in_stage + 1,
            'final_loss':     final_loss,
            'early_stopped':  early_stop,
            'loss_history':   stage_losses
        }
        
        print(f"‚úÖ === √âTAPE {stage_nb} - TERMIN√âE ===")
        print(f"üìä √âpoques entra√Æn√©es: {epoch_in_stage + 1}/{max_epochs}")
        print(f"üìâ Perte finale: {final_loss:.6f}")
        print(f"‚ö° Arr√™t pr√©coce: {'‚úÖ OUI' if early_stop else '‚ùå NON'}")
        
        # Sauvegarde du checkpoint d'√©tape
        stage = STAGE_MANAGER.get_stage(stage_nb)
        stage.save_stage_checkpoint(stage_metrics, self.model.state_dict(), self.optimizer.state_dict())
        
        # Lib√©ration du cache de l'√©tape pr√©c√©dente pour √©conomiser la m√©moire
        if self.use_cache and stage_nb > 1:
            self.sequence_cache.clear_stage_cache(stage_nb - 1)
        
        return stage_metrics
    
    
    def train_full_curriculum(self) -> Dict[str, Any]:
        """
        Entra√Ænement complet du curriculum en 3 √©tapes.

        Returns:
            M√©triques compl√®tes de l'entra√Ænement modulaire
        """
        print(f"\nüöÄ === D√âBUT ENTRA√éNEMENT MODULAIRE ===")
        print(f"üéØ Seed: {SEED}")
        print(f"üìä √âpoques totales pr√©vues: {CONFIG.TOTAL_EPOCHS}")
        print(f"üîÑ √âtapes: {CONFIG.STAGE_1_EPOCHS} + {CONFIG.STAGE_2_EPOCHS} + {CONFIG.STAGE_3_EPOCHS}")
        
        start_time = time.time()
        self.model.train()
        
        # Entra√Ænement s√©quentiel des 3 √©tapes
        all_stage_metrics = {}
        
        # √âTAPE 1: Sans obstacles
        stage_1_metrics = self.train_stage(1, CONFIG.STAGE_1_EPOCHS)
        all_stage_metrics[1] = stage_1_metrics
        
        # √âTAPE 2: Un obstacle
        stage_2_metrics = self.train_stage(2, CONFIG.STAGE_2_EPOCHS)
        all_stage_metrics[2] = stage_2_metrics
        
        # √âTAPE 3: Obstacles multiples
        stage_3_metrics = self.train_stage(3, CONFIG.STAGE_3_EPOCHS)
        all_stage_metrics[3] = stage_3_metrics
        
        # M√©triques globales
        total_time = time.time() - start_time
        total_epochs_actual = sum(metrics['epochs_trained'] for metrics in all_stage_metrics.values())
        
        global_metrics = {
            'total_epochs_planned': CONFIG.TOTAL_EPOCHS,
            'total_epochs_actual':  total_epochs_actual,
            'total_time_seconds':   total_time,
            'total_time_formatted': f"{total_time / 60:.1f} min",
            'stage_metrics':        all_stage_metrics,
            'final_loss':           stage_3_metrics['final_loss'],
            'global_history':       self.global_history,
            'stage_histories':      self.stage_histories,
            'stage_start_epochs':   self.stage_start_epochs  # AJOUT de la cl√© manquante
        }
        
        print(f"\nüéâ === ENTRA√éNEMENT MODULAIRE TERMIN√â ===")
        print(f"‚è±Ô∏è  Temps total: {total_time / 60:.1f} minutes")
        print(f"üìä √âpoques totales: {total_epochs_actual}/{CONFIG.TOTAL_EPOCHS}")
        print(f"üìâ Perte finale: {global_metrics['final_loss']:.6f}")
        
        # Sauvegarde du mod√®le final et des m√©triques
        self.save_final_model(global_metrics)
        
        return global_metrics
    
    
    def save_final_model(self, global_metrics: Dict[str, Any]):
        """Sauvegarde le mod√®le final et toutes les m√©triques."""
        # Mod√®le final
        final_model_path = Path(CONFIG.OUTPUT_DIR) / "final_model.pth"
        torch.save({
            'model_state_dict':     self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'global_metrics':       global_metrics,
            'config':               CONFIG.__dict__
        }, final_model_path)
        
        # M√©triques compl√®tes
        full_metrics_path = Path(CONFIG.OUTPUT_DIR) / "complete_metrics.json"
        with open(full_metrics_path, 'w') as f:
            json.dump(global_metrics, f, indent=2, default=str)
        
        print(f"üíæ Mod√®le final et m√©triques sauvegard√©s: {CONFIG.OUTPUT_DIR}")



def main():
    """
    Fonction principale pour l'entra√Ænement modulaire progressif.
    Orchestre tout le processus d'apprentissage par curriculum.
    """
    print(f"\n" + "=" * 80)
    print(f"üöÄ NEURAL CELLULAR AUTOMATON - APPRENTISSAGE MODULAIRE v7__")
    print(f"=" * 80)
    
    try:
        # Initialisation du mod√®le
        print("\nüîß Initialisation du mod√®le...")
        model = ImprovedNCA(
                input_size=11,  # 9 (patch 3x3) + 1 (source) + 1 (obstacle)
        ).to(DEVICE)
        
        print(f"üìä Nombre de param√®tres dans le mod√®le: {sum(p.numel() for p in model.parameters()):,}")
        
        # Initialisation de l'entra√Æneur modulaire
        print("üéØ Initialisation de l'entra√Æneur modulaire...")
        trainer = ModularTrainer(model)
        
        # Lancement de l'entra√Ænement complet
        print("üöÄ Lancement de l'entra√Ænement modulaire...")
        global_metrics = trainer.train_full_curriculum()
        
        # G√©n√©ration des visualisations progressives
        print("\nüé® G√©n√©ration des visualisations...")
        from visualizer import ProgressiveVisualizer
        visualizer = ProgressiveVisualizer()
        
        # Visualisation par √©tape avec le mod√®le final
        for stage_nb in [1, 2, 3]:
            visualizer.visualize_stage_results(model, stage_nb)
        
        # R√©sum√© visuel complet du curriculum
        visualizer.create_curriculum_summary(global_metrics)
        
        # Rapport final
        print(f"\n" + "=" * 80)
        print(f"üéâ ENTRA√éNEMENT MODULAIRE TERMIN√â AVEC SUCC√àS!")
        print(f"=" * 80)
        print(f"üìÅ R√©sultats sauvegard√©s dans: {CONFIG.OUTPUT_DIR}")
        print(f"‚è±Ô∏è  Temps total: {global_metrics['total_time_formatted']}")
        print(f"üìä √âpoques: {global_metrics['total_epochs_actual']}/{global_metrics['total_epochs_planned']}")
        print(f"üìâ Perte finale: {global_metrics['final_loss']:.6f}")
        
        # D√©tail par √©tape
        print(f"\nüìã D√âTAIL PAR √âTAPE:")
        for stage in STAGE_MANAGER.get_stages():
            stage_data = global_metrics['stage_metrics'][stage.get_stage_nb()]
            print(f"   √âtape {stage_nb} ({stage.get_display_name()}): {stage_data['final_loss']:.6f}")
        
        print(f"\nüé® Fichiers de visualisation g√©n√©r√©s:")
        print(f"   ‚Ä¢ Animations par √©tape: stage_X/")
        print(f"   ‚Ä¢ Progression curriculum: curriculum_progression.png")
        print(f"   ‚Ä¢ Comparaison √©tapes: stage_comparison.png")
        print(f"   ‚Ä¢ R√©sum√© performance: performance_summary.png")
        print(f"   ‚Ä¢ M√©triques compl√®tes: complete_metrics.json")
        
        return global_metrics
    
    except KeyboardInterrupt:
        print(f"\n‚ö†Ô∏è  Entra√Ænement interrompu par l'utilisateur")
        return None
    except Exception as e:
        print(f"\n‚ùå ERREUR lors de l'entra√Ænement:")
        print(f"   {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # Ex√©cution du programme principal
    results = main()
    
    if results is not None:
        print(f"\nüéØ Programme termin√© avec succ√®s!")
        print(f"üìä R√©sultats disponibles dans la variable 'results'")
    else:
        print(f"\n‚ùå Programme termin√© avec erreurs")
        exit(1)
