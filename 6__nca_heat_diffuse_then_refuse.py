import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import matplotlib.pyplot as plt
import matplotlib
import numpy as np
from typing import Tuple, List, Optional
import os
import argparse

# =============================================================================
# Configuration et initialisation
# =============================================================================

class Config:
    """
    Configuration centralis√©e pour tous les param√®tres du mod√®le.
    Facilite les exp√©rimentations et la reproductibilit√©.
    """
    def __init__(self, seed: int = 123):
        # Param√®tres mat√©riels
        self.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
        self.SEED = seed  # Seed configurable via argument

        # Param√®tres de grille
        self.GRID_SIZE = 16
        self.SOURCE_INTENSITY = 1.0

        # Param√®tres d'entra√Ænement
        self.N_EPOCHS = 100  # Augment√© pour un meilleur apprentissage
        self.NCA_STEPS = 20  # Horizon temporel pour l'apprentissage multi-step
        self.LEARNING_RATE = 1e-3
        self.BATCH_SIZE = 4  # Entra√Ænement par batch pour plus de stabilit√©

        # Param√®tres de visualisation
        self.PREVIS_STEPS = 30
        self.POSTVIS_STEPS = 50
        self.SAVE_ANIMATIONS = True  # Sauvegarde des animations si pas d'affichage interactif
        self.OUTPUT_DIR = "6__nca_outputs_heat_diffuse_then_refuse"  # Nouveau r√©pertoire pour les r√©sultats heat diffuse then refuse

        # Param√®tres du mod√®le
        self.HIDDEN_SIZE = 128  # Augment√© pour plus de capacit√©
        self.N_LAYERS = 3

        # Nouveaux param√®tres pour les obstacles
        self.MIN_OBSTACLES = 1  # Nombre minimum d'obstacles
        self.MAX_OBSTACLES = 3  # Nombre maximum d'obstacles
        self.MIN_OBSTACLE_SIZE = 2  # Taille minimale d'un obstacle (carr√© NxN)
        self.MAX_OBSTACLE_SIZE = 4  # Taille maximale d'un obstacle
        
        # Param√®tres d'optimisation (NOUVEAUX)
        self.USE_OPTIMIZATIONS = True  # Activer les optimisations de performance
        self.USE_SEQUENCE_CACHE = True  # Utiliser le cache de s√©quences pr√©-calcul√©es
        self.USE_VECTORIZED_PATCHES = True  # Utiliser l'extraction vectoris√©e des patches
        self.CACHE_SIZE = 200  # Nombre de s√©quences dans le cache
        self.USE_MIXED_PRECISION = False  # Mixed precision (fp16) - peut causer des instabilit√©s

def parse_arguments():
    """
    Parse les arguments de ligne de commande pour la configuration.

    Returns:
        Namespace avec les arguments pars√©s
    """
    parser = argparse.ArgumentParser(
        description='Neural Cellular Automaton - Diffusion de chaleur avec obstacles',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    parser.add_argument(
        '--seed',
        type=int,
        default=123,
        help='Graine al√©atoire pour la reproductibilit√© des exp√©riences (entra√Ænement)'
    )

    parser.add_argument(
        '--vis-seed',
        type=int,
        default=3333,
        help='Graine al√©atoire pour la s√©quence de visualisation (ind√©pendante de l\'entra√Ænement)'
    )

    parser.add_argument(
        '--epochs',
        type=int,
        default=100,
        help='Nombre d\'√©poques d\'entra√Ænement'
    )

    parser.add_argument(
        '--grid-size',
        type=int,
        default=16,
        help='Taille de la grille de simulation'
    )

    parser.add_argument(
        '--batch-size',
        type=int,
        default=4,
        help='Taille des batches d\'entra√Ænement'
    )

    return parser.parse_args()

# Parse des arguments au d√©but
args = parse_arguments()

# Configuration globale avec seed personnalisable
cfg = Config(seed=args.seed)

# Mise √† jour des param√®tres depuis les arguments
cfg.N_EPOCHS = args.epochs
cfg.GRID_SIZE = args.grid_size
cfg.BATCH_SIZE = args.batch_size

# Gestion du backend matplotlib pour l'affichage interactif
def setup_matplotlib():
    """
    Configure matplotlib pour l'affichage interactif ou la sauvegarde.
    D√©tecte automatiquement si l'environnement supporte l'interactivit√©.
    """
    try:
        # Teste si on peut utiliser un backend interactif
        matplotlib.use('Qt5Agg')
        plt.ion()
        # Test simple pour v√©rifier que l'affichage fonctionne
        fig, ax = plt.subplots()
        plt.close(fig)
        print("‚úÖ Mode interactif activ√©")
        return True
    except:
        try:
            matplotlib.use('TkAgg')
            plt.ion()
            fig, ax = plt.subplots()
            plt.close(fig)
            print("‚úÖ Mode interactif activ√© (TkAgg)")
            return True
        except:
            print("‚ö†Ô∏è  Mode non-interactif d√©tect√© - les animations seront sauvegard√©es")
            matplotlib.use('Agg')
            return False

# Initialisation
interactive_mode = setup_matplotlib()
if os.name == 'nt':
    interactive_mode = False  # not manage for windows
torch.manual_seed(cfg.SEED)
np.random.seed(cfg.SEED)

# Cr√©ation du dossier de sortie avec seed dans le nom pour diff√©rencier
cfg.OUTPUT_DIR = f"6__nca_outputs_heat_diffuse_then_refuse_seed_{cfg.SEED}"
if cfg.SAVE_ANIMATIONS:
    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)

print(f"Device: {cfg.DEVICE}")
print(f"Seed: {cfg.SEED}")
print(f"Mode interactif: {interactive_mode}")
print(f"R√©pertoire de sortie: {cfg.OUTPUT_DIR}")

# =============================================================================
# Simulation physique cible (diffusion de chaleur avec obstacles)
# =============================================================================

class DiffusionSimulator:
    """
    Simulateur de diffusion de chaleur bas√© sur convolution avec obstacles.
    Repr√©sente le processus physique que le NCA doit apprendre √† reproduire.
    Les obstacles bloquent compl√®tement la diffusion de chaleur.
    """
    def __init__(self, device: str = cfg.DEVICE):
        # Kernel de diffusion : moyenne des 8 voisins + centre
        # Simule l'√©quation de diffusion de chaleur discr√©tis√©e
        self.kernel = torch.ones((1, 1, 3, 3), device=device) / 9.0
        self.device = device

    def generate_obstacles(self, size: int, source_pos: Tuple[int, int], seed: Optional[int] = None) -> torch.Tensor:
        """
        G√©n√®re des obstacles al√©atoirement plac√©s dans la grille.

        Args:
            size: Taille de la grille
            source_pos: Position de la source de chaleur (i, j) √† √©viter
            seed: Graine pour la reproductibilit√©

        Returns:
            Masque des obstacles [H, W] (True = obstacle)
        """
        if seed is not None:
            g = torch.Generator(device=self.device)
            g.manual_seed(seed)
        else:
            g = None

        obstacle_mask = torch.zeros((size, size), dtype=torch.bool, device=self.device)

        # Nombre d'obstacles al√©atoire
        n_obstacles = torch.randint(cfg.MIN_OBSTACLES, cfg.MAX_OBSTACLES + 1, (1,),
                                   generator=g, device=self.device).item()

        for _ in range(n_obstacles):
            # Taille de l'obstacle al√©atoire
            obstacle_size = torch.randint(cfg.MIN_OBSTACLE_SIZE, cfg.MAX_OBSTACLE_SIZE + 1, (1,),
                                        generator=g, device=self.device).item()

            # Position al√©atoire pour l'obstacle (en √©vitant les bords)
            max_pos = size - obstacle_size
            if max_pos <= 1:
                continue  # Obstacle trop grand pour la grille

            for attempt in range(50):  # Maximum 50 tentatives pour placer l'obstacle
                i = torch.randint(1, max_pos, (1,), generator=g, device=self.device).item()
                j = torch.randint(1, max_pos, (1,), generator=g, device=self.device).item()

                # V√©rifier que l'obstacle ne chevauche pas avec la source
                source_i, source_j = source_pos
                if not (i <= source_i < i + obstacle_size and j <= source_j < j + obstacle_size):
                    # Placer l'obstacle
                    obstacle_mask[i:i+obstacle_size, j:j+obstacle_size] = True
                    break

        return obstacle_mask

    def step(self, grid: torch.Tensor, source_mask: torch.Tensor, obstacle_mask: torch.Tensor) -> torch.Tensor:
        """
        Un pas de diffusion de chaleur avec conditions aux bords, sources fixes et obstacles.

        Args:
            grid: Grille de temp√©rature [H, W]
            source_mask: Masque des sources de chaleur [H, W]
            obstacle_mask: Masque des obstacles [H, W]

        Returns:
            Nouvelle grille apr√®s diffusion de chaleur
        """
        # Ajout des dimensions batch et channel pour la convolution
        x = grid.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]

        # Convolution avec padding pour conserver la taille
        new_grid = F.conv2d(x, self.kernel, padding=1).squeeze(0).squeeze(0)

        # Les obstacles restent √† 0 (pas de diffusion de chaleur)
        new_grid[obstacle_mask] = 0.0

        # Les sources de chaleur restent √† intensit√© constante (condition de Dirichlet)
        new_grid[source_mask] = grid[source_mask]

        return new_grid

    def generate_sequence(self, n_steps: int, size: int, seed: Optional[int] = None) -> Tuple[List[torch.Tensor], torch.Tensor, torch.Tensor]:
        """
        G√©n√®re une s√©quence compl√®te de diffusion de chaleur avec source et obstacles al√©atoires.

        Args:
            n_steps: Nombre d'√©tapes de simulation
            size: Taille de la grille
            seed: Graine pour la reproductibilit√©

        Returns:
            Liste des √©tats de la grille de temp√©rature, masque de la source de chaleur, masque des obstacles
        """
        # Positionnement al√©atoire de la source (√©vite les bords)
        if seed is not None:
            g = torch.Generator(device=self.device)
            g.manual_seed(seed)
            i0 = torch.randint(2, size-2, (1,), generator=g, device=self.device).item()
            j0 = torch.randint(2, size-2, (1,), generator=g, device=self.device).item()
        else:
            i0 = torch.randint(2, size-2, (1,), device=self.device).item()
            j0 = torch.randint(2, size-2, (1,), device=self.device).item()

        # G√©n√©ration des obstacles en √©vitant la source
        obstacle_mask = self.generate_obstacles(size, (i0, j0), seed)

        # Initialisation de la grille et du masque source
        grid = torch.zeros((size, size), device=self.device)
        grid[i0, j0] = cfg.SOURCE_INTENSITY

        source_mask = torch.zeros_like(grid, dtype=torch.bool)
        source_mask[i0, j0] = True

        # S'assurer que la source n'est pas dans un obstacle
        if obstacle_mask[i0, j0]:
            obstacle_mask[i0, j0] = False

        # Simulation temporelle
        sequence = [grid.clone()]
        for _ in range(n_steps):
            grid = self.step(grid, source_mask, obstacle_mask)
            sequence.append(grid.clone())

        return sequence, source_mask, obstacle_mask

# Instance globale du simulateur
simulator = DiffusionSimulator()

# =============================================================================
# Mod√®le Neural Cellular Automaton
# =============================================================================

class ImprovedNCA(nn.Module):
    """
    Neural Cellular Automaton am√©lior√© avec architecture plus robuste.

    Am√©liorations par rapport √† la version originale :
    - Architecture plus profonde et flexible
    - Normalisation par batch pour la stabilit√©
    - Dropout pour la r√©gularisation
    - Activation plus stable (ReLU au lieu de tanh)
    - Gestion du gradient clipping int√©gr√©e
    - Support pour les obstacles
    """
    def __init__(self, input_size: int = 11, hidden_size: int = cfg.HIDDEN_SIZE, n_layers: int = cfg.N_LAYERS):  # 11 au lieu de 10 pour inclure l'info obstacle
        super().__init__()

        self.input_size = input_size
        self.hidden_size = hidden_size
        self.n_layers = n_layers

        # Construction dynamique du r√©seau
        layers = []
        current_size = input_size

        for i in range(n_layers):
            layers.append(nn.Linear(current_size, hidden_size))
            layers.append(nn.BatchNorm1d(hidden_size))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(0.1))  # R√©gularisation l√©g√®re
            current_size = hidden_size

        # Couche de sortie : produit un delta dans [-0.1, 0.1] pour la stabilit√©
        layers.append(nn.Linear(hidden_size, 1))
        layers.append(nn.Tanh())

        self.network = nn.Sequential(*layers)

        # Facteur d'√©chelle pour limiter les changements brutaux
        self.delta_scale = 0.1

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward pass du r√©seau.

        Args:
            x: Patch d'entr√©e [B, input_size]

        Returns:
            Delta √† appliquer [B, 1]
        """
        delta = self.network(x)
        return delta * self.delta_scale

class NCAUpdater:
    """
    Classe responsable de l'application du mod√®le NCA sur une grille avec obstacles.
    S√©pare la logique de mise √† jour de l'architecture du mod√®le.
    """
    def __init__(self, model: ImprovedNCA, device: str = cfg.DEVICE):
        self.model = model
        self.device = device

    def step(self, grid: torch.Tensor, source_mask: torch.Tensor, obstacle_mask: torch.Tensor) -> torch.Tensor:
        """
        Application du NCA sur toute la grille avec prise en compte des obstacles.

        Args:
            grid: Grille courante [H, W]
            source_mask: Masque des sources [H, W]
            obstacle_mask: Masque des obstacles [H, W]

        Returns:
            Nouvelle grille apr√®s application du NCA
        """
        H, W = grid.shape
        new_grid = grid.clone()

        # Collecte de tous les patches pour traitement par batch
        patches = []
        positions = []

        for i in range(1, H-1):
            for j in range(1, W-1):
                # Skip si c'est un obstacle
                if obstacle_mask[i, j]:
                    continue

                # Extraction du patch 3x3 autour de (i,j)
                patch = grid[i-1:i+2, j-1:j+2].reshape(-1)  # 9 √©l√©ments
                # Ajout de l'information "est source" comme feature
                is_source = source_mask[i, j].float()
                # Ajout de l'information "est obstacle" comme feature
                is_obstacle = obstacle_mask[i, j].float()
                full_patch = torch.cat([patch, is_source.unsqueeze(0), is_obstacle.unsqueeze(0)])  # 11 √©l√©ments

                patches.append(full_patch)
                positions.append((i, j))

        if patches:
            # Traitement par batch pour l'efficacit√©
            patches_tensor = torch.stack(patches)  # [N, 11]
            deltas = self.model(patches_tensor)  # [N, 1]

            # Application des deltas
            for idx, (i, j) in enumerate(positions):
                new_value = grid[i, j] + deltas[idx].squeeze()
                new_grid[i, j] = torch.clamp(new_value, 0.0, 1.0)

        # Les obstacles restent √† 0
        new_grid[obstacle_mask] = 0.0

        # Les sources restent fixes
        new_grid[source_mask] = grid[source_mask]

        return new_grid

class OptimizedNCAUpdater:
    """
    Version optimis√©e du NCAUpdater utilisant des convolutions pour l'extraction vectoris√©e des patches.
    Remplace les boucles Python par des op√©rations GPU natives pour un gain de performance majeur.
    """
    def __init__(self, model: ImprovedNCA, device: str = cfg.DEVICE):
        self.model = model
        self.device = device
        
    def step(self, grid: torch.Tensor, source_mask: torch.Tensor, obstacle_mask: torch.Tensor) -> torch.Tensor:
        """
        Application optimis√©e du NCA sur toute la grille avec extraction vectoris√©e des patches.
        
        Args:
            grid: Grille courante [H, W]
            source_mask: Masque des sources [H, W]
            obstacle_mask: Masque des obstacles [H, W]
            
        Returns:
            Nouvelle grille apr√®s application du NCA
        """
        H, W = grid.shape
        
        # Extraction de tous les patches 3x3 en une seule op√©ration vectoris√©e
        grid_padded = F.pad(grid.unsqueeze(0).unsqueeze(0), (1, 1, 1, 1), mode='replicate')  # [1, 1, H+2, W+2]
        
        # Unfold pour extraire tous les patches 3x3 simultan√©ment
        patches = F.unfold(grid_padded, kernel_size=3, stride=1)  # [1, 9, H*W]
        patches = patches.squeeze(0).transpose(0, 1)  # [H*W, 9]
        
        # Masques aplatis pour filtrer les positions valides
        source_flat = source_mask.flatten()  # [H*W]
        obstacle_flat = obstacle_mask.flatten()  # [H*W]
        
        # Cr√©ation des features additionnelles (source et obstacle info)
        source_features = source_flat.float().unsqueeze(1)  # [H*W, 1]
        obstacle_features = obstacle_flat.float().unsqueeze(1)  # [H*W, 1]
        
        # Concat√©nation des patches avec les features : [H*W, 11]
        full_patches = torch.cat([patches, source_features, obstacle_features], dim=1)
        
        # Masque pour les positions o√π le NCA peut s'appliquer (pas d'obstacles)
        valid_mask = ~obstacle_flat  # [H*W]
        
        # Application du mod√®le seulement sur les positions valides
        if valid_mask.any():
            valid_patches = full_patches[valid_mask]  # [N_valid, 11]
            deltas = self.model(valid_patches)  # [N_valid, 1]
            
            # Reconstruction de la grille avec les deltas
            new_grid = grid.clone().flatten()  # [H*W]
            new_grid[valid_mask] += deltas.squeeze()
            new_grid = torch.clamp(new_grid, 0.0, 1.0).reshape(H, W)
        else:
            new_grid = grid.clone()
        
        # Application des contraintes
        new_grid[obstacle_mask] = 0.0  # Les obstacles restent √† 0
        new_grid[source_mask] = grid[source_mask]  # Les sources restent fixes
        
        return new_grid

# =============================================================================
# Syst√®me d'entra√Ænement
# =============================================================================

class NCATrainer:
    """
    Syst√®me d'entra√Ænement pour le NCA avec fonctionnalit√©s avanc√©es et obstacles.

    Features :
    - Entra√Ænement par batch
    - Gradient clipping automatique
    - Scheduling du learning rate
    - M√©triques d√©taill√©es
    - Sauvegarde automatique
    - Support pour les obstacles
    """
    def __init__(self, model: ImprovedNCA, device: str = cfg.DEVICE):
        self.model = model
        self.device = device
        self.updater = NCAUpdater(model, device)

        # Optimiseur avec weight decay pour la r√©gularisation
        self.optimizer = optim.AdamW(model.parameters(), lr=cfg.LEARNING_RATE, weight_decay=1e-4)

        # Scheduler pour r√©duire le learning rate progressivement
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=cfg.N_EPOCHS)

        # Fonction de perte
        self.loss_fn = nn.MSELoss()

        # Historiques
        self.loss_history = []
        self.lr_history = []

    def train_step(self, target_sequence: List[torch.Tensor], source_mask: torch.Tensor, obstacle_mask: torch.Tensor) -> float:
        """
        Un pas d'entra√Ænement sur une s√©quence cible avec obstacles.

        Args:
            target_sequence: S√©quence cible [T+1, H, W]
            source_mask: Masque des sources [H, W]
            obstacle_mask: Masque des obstacles [H, W]

        Returns:
            Perte moyenne sur la s√©quence
        """
        self.optimizer.zero_grad()

        # Initialisation : grille vide avec sources
        grid_pred = torch.zeros_like(target_sequence[0])
        grid_pred[source_mask] = cfg.SOURCE_INTENSITY

        total_loss = torch.tensor(0.0, device=self.device)

        # D√©roulement temporel avec calcul de perte √† chaque √©tape
        for t_step in range(cfg.NCA_STEPS):
            target = target_sequence[t_step + 1]

            # Application du NCA
            grid_pred = self.updater.step(grid_pred, source_mask, obstacle_mask)

            # Accumulation de la perte
            step_loss = self.loss_fn(grid_pred, target)
            total_loss = total_loss + step_loss

        # Perte moyenne sur la s√©quence
        avg_loss = total_loss / cfg.NCA_STEPS

        # Backpropagation avec gradient clipping
        avg_loss.backward()
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)

        self.optimizer.step()

        return avg_loss.item()

# =============================================================================
# Syst√®me d'entra√Ænement optimis√©
# =============================================================================

class OptimizedSequenceCache:
    """
    Cache optimis√© pour les s√©quences d'entra√Ænement.
    Pr√©-g√©n√®re et stocke les s√©quences sur GPU pour √©viter la recomputation.
    """
    def __init__(self, simulator: DiffusionSimulator, n_sequences: int = 200, device: str = cfg.DEVICE):
        self.simulator = simulator
        self.device = device
        self.n_sequences = n_sequences
        self.sequences = []
        self.current_idx = 0
        
        print(f"üöÄ G√©n√©ration de {n_sequences} s√©quences d'entra√Ænement...")
        self._generate_sequences()
        print("‚úÖ Cache des s√©quences cr√©√© !")
    
    def _generate_sequences(self):
        """Pr√©-g√©n√®re toutes les s√©quences d'entra√Ænement."""
        for i in range(self.n_sequences):
            if i % 50 == 0:
                print(f"   G√©n√©ration: {i}/{self.n_sequences}")
            
            # G√©n√©ration d'une s√©quence avec configuration al√©atoire
            target_seq, source_mask, obstacle_mask = self.simulator.generate_sequence(
                n_steps=cfg.NCA_STEPS,
                size=cfg.GRID_SIZE
            )
            
            # Stockage sur GPU pour acc√®s rapide
            self.sequences.append({
                'target_seq': target_seq,  # D√©j√† sur GPU
                'source_mask': source_mask,
                'obstacle_mask': obstacle_mask
            })
    
    def get_batch(self, batch_size: int):
        """
        R√©cup√®re un batch de s√©quences du cache.
        
        Args:
            batch_size: Taille du batch demand√©
            
        Returns:
            Liste de dictionnaires avec les s√©quences
        """
        batch = []
        for _ in range(batch_size):
            # R√©cup√©ration cyclique des s√©quences
            batch.append(self.sequences[self.current_idx])
            self.current_idx = (self.current_idx + 1) % self.n_sequences
        
        return batch
    
    def shuffle(self):
        """M√©lange l'ordre des s√©quences pour plus de vari√©t√©."""
        import random
        random.shuffle(self.sequences)

class NCATrainer:
    """
    Syst√®me d'entra√Ænement pour le NCA avec fonctionnalit√©s avanc√©es et obstacles.

    Features :
    - Entra√Ænement par batch optimis√©
    - Cache de s√©quences pr√©-calcul√©es
    - Gradient clipping automatique
    - Scheduling du learning rate
    - M√©triques d√©taill√©es
    - Sauvegarde automatique
    - Support pour les obstacles
    """
    def __init__(self, model: ImprovedNCA, device: str = cfg.DEVICE):
        self.model = model
        self.device = device
        
        # Choix de l'updater selon les optimisations activ√©es
        if cfg.USE_OPTIMIZATIONS and cfg.USE_VECTORIZED_PATCHES:
            print("üöÄ Utilisation de l'updater optimis√© (extraction vectoris√©e)")
            self.updater = OptimizedNCAUpdater(model, device)
        else:
            print("‚ö†Ô∏è  Utilisation de l'updater standard (boucles Python)")
            self.updater = NCAUpdater(model, device)

        # Optimiseur avec weight decay pour la r√©gularisation
        self.optimizer = optim.AdamW(model.parameters(), lr=cfg.LEARNING_RATE, weight_decay=1e-4)

        # Scheduler pour r√©duire le learning rate progressivement
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=cfg.N_EPOCHS)

        # Fonction de perte
        self.loss_fn = nn.MSELoss()

        # Historiques
        self.loss_history = []
        self.lr_history = []
        
        # Cache de s√©quences optimis√©
        if cfg.USE_OPTIMIZATIONS and cfg.USE_SEQUENCE_CACHE:
            print("üéØ Initialisation du cache de s√©quences optimis√©...")
            self.sequence_cache = OptimizedSequenceCache(simulator, n_sequences=cfg.CACHE_SIZE, device=device)
            self.use_cache = True
        else:
            print("‚ö†Ô∏è  Cache de s√©quences d√©sactiv√© - g√©n√©ration √† la vol√©e")
            self.use_cache = False

    def train_step(self, target_sequence: List[torch.Tensor], source_mask: torch.Tensor, obstacle_mask: torch.Tensor) -> float:
        """
        Un pas d'entra√Ænement sur une s√©quence cible avec obstacles.

        Args:
            target_sequence: S√©quence cible [T+1, H, W]
            source_mask: Masque des sources [H, W]
            obstacle_mask: Masque des obstacles [H, W]

        Returns:
            Perte moyenne sur la s√©quence
        """
        self.optimizer.zero_grad()

        # Initialisation : grille vide avec sources
        grid_pred = torch.zeros_like(target_sequence[0])
        grid_pred[source_mask] = cfg.SOURCE_INTENSITY

        total_loss = torch.tensor(0.0, device=self.device)

        # D√©roulement temporel avec calcul de perte √† chaque √©tape
        for t_step in range(cfg.NCA_STEPS):
            target = target_sequence[t_step + 1]

            # Application du NCA
            grid_pred = self.updater.step(grid_pred, source_mask, obstacle_mask)

            # Accumulation de la perte
            step_loss = self.loss_fn(grid_pred, target)
            total_loss = total_loss + step_loss

        # Perte moyenne sur la s√©quence
        avg_loss = total_loss / cfg.NCA_STEPS

        # Backpropagation avec gradient clipping
        avg_loss.backward()
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)

        self.optimizer.step()

        return avg_loss.item()
    
    def train_batch_optimized(self, batch_sequences: List[dict]) -> float:
        """
        Entra√Ænement optimis√© sur un batch de s√©quences pr√©-calcul√©es.
        
        Args:
            batch_sequences: Liste de dictionnaires avec les s√©quences
            
        Returns:
            Perte moyenne du batch
        """
        batch_losses = []
        
        for seq_data in batch_sequences:
            target_seq = seq_data['target_seq']
            source_mask = seq_data['source_mask']
            obstacle_mask = seq_data['obstacle_mask']
            
            loss = self.train_step(target_seq, source_mask, obstacle_mask)
            batch_losses.append(loss)
        
        return sum(batch_losses) / len(batch_losses)

    def train(self) -> None:
        """
        Boucle d'entra√Ænement principale avec batch training optimis√© et obstacles.
        """
        if self.use_cache:
            print("üöÄ D√©but de l'entra√Ænement OPTIMIS√â avec obstacles...")
        else:
            print("üöÄ D√©but de l'entra√Ænement STANDARD avec obstacles...")
            
        self.model.train()

        for epoch in range(cfg.N_EPOCHS):
            epoch_losses = []
            
            # M√©lange du cache √† chaque √©poque pour plus de vari√©t√© (si cache activ√©)
            if self.use_cache and epoch % 10 == 0:
                self.sequence_cache.shuffle()

            # Entra√Ænement par batch
            for batch_idx in range(cfg.BATCH_SIZE):
                if self.use_cache:
                    # Version optimis√©e : r√©cup√©ration rapide depuis le cache
                    batch_sequences = self.sequence_cache.get_batch(1)
                    avg_loss = self.train_batch_optimized(batch_sequences)
                else:
                    # Version standard : g√©n√©ration √† la vol√©e
                    target_seq, source_mask, obstacle_mask = simulator.generate_sequence(
                        n_steps=cfg.NCA_STEPS,
                        size=cfg.GRID_SIZE
                    )
                    avg_loss = self.train_step(target_seq, source_mask, obstacle_mask)
                
                epoch_losses.append(avg_loss)

            # Statistiques de l'√©poque
            avg_epoch_loss = np.mean(epoch_losses)
            self.loss_history.append(avg_epoch_loss)
            self.lr_history.append(self.scheduler.get_last_lr()[0])

            # Mise √† jour du learning rate
            self.scheduler.step()

            # Affichage p√©riodique
            if epoch % 20 == 0 or epoch == cfg.N_EPOCHS - 1:
                optimization_info = "OPTIMIS√â" if self.use_cache else "STANDARD"
                print(f"Epoch {epoch:3d}/{cfg.N_EPOCHS-1} | "
                      f"Loss: {avg_epoch_loss:.6f} | "
                      f"LR: {self.scheduler.get_last_lr()[0]:.2e} | "
                      f"Mode: {optimization_info}")

        if self.use_cache:
            print("‚úÖ Entra√Ænement optimis√© termin√©!")
        else:
            print("‚úÖ Entra√Ænement standard termin√©!")

# =============================================================================
# Syst√®me de visualisation avanc√©
# =============================================================================

class NCAVisualizer:
    """
    Syst√®me de visualisation avanc√© avec support pour mode interactif et sauvegarde avec obstacles.
    """
    def __init__(self, interactive: bool = interactive_mode):
        self.interactive = interactive
        self.frame_data = []  # Pour sauvegarder les animations

    def animate_comparison(self, updater: NCAUpdater, target_sequence: List[torch.Tensor],
                          source_mask: torch.Tensor, obstacle_mask: torch.Tensor, title_prefix: str, n_steps: int) -> None:
        """
        Animation comparative entre NCA et simulation cible avec obstacles.

        Args:
            updater: Syst√®me de mise √† jour NCA
            target_sequence: S√©quence de r√©f√©rence
            source_mask: Masque des sources
            obstacle_mask: Masque des obstacles
            title_prefix: Pr√©fixe pour le titre
            n_steps: Nombre d'√©tapes √† animer
        """
        # Initialisation de la grille NCA
        grid_nca = torch.zeros_like(target_sequence[0])
        grid_nca[source_mask] = cfg.SOURCE_INTENSITY

        if self.interactive:
            # Mode interactif
            plt.ion()
            fig, axes = plt.subplots(1, 3, figsize=(18, 5))

            im_nca = axes[0].imshow(grid_nca.cpu().numpy(), cmap="plasma", vmin=0, vmax=1)
            axes[0].set_title("NCA")
            axes[0].set_xlabel("Position X")
            axes[0].set_ylabel("Position Y")

            target_final = target_sequence[min(len(target_sequence)-1, n_steps)]
            im_target = axes[1].imshow(target_final.cpu().numpy(), cmap="plasma", vmin=0, vmax=1)
            axes[1].set_title("Cible (√©tat final)")
            axes[1].set_xlabel("Position X")
            axes[1].set_ylabel("Position Y")

            # Visualisation des obstacles
            obstacle_vis = obstacle_mask.cpu().numpy().astype(float)
            obstacle_vis[obstacle_vis == 0] = np.nan  # Transparent pour les zones libres
            im_obstacles = axes[2].imshow(obstacle_vis, cmap="Greys", alpha=0.8)
            axes[2].set_title("Obstacles")
            axes[2].set_xlabel("Position X")
            axes[2].set_ylabel("Position Y")

            # Ajout de barres de couleur
            fig.colorbar(im_nca, ax=axes[0], label="Intensit√©")
            fig.colorbar(im_target, ax=axes[1], label="Intensit√©")

            plt.tight_layout()

            for step in range(n_steps):
                grid_nca = updater.step(grid_nca, source_mask, obstacle_mask)
                im_nca.set_data(grid_nca.cpu().numpy())
                plt.suptitle(f"{title_prefix} ‚Äî √âtape {step+1}/{n_steps}")
                if self.interactive:
                    plt.draw()
                    plt.pause(0.05)

            if self.interactive:
                plt.pause(1.0)
            plt.close(fig)
            plt.ioff()

        else:
            # Mode sauvegarde
            frames = []
            target_final = target_sequence[min(len(target_sequence)-1, n_steps)]

            for step in range(n_steps):
                grid_nca = updater.step(grid_nca, source_mask, obstacle_mask)

                # Sauvegarde des donn√©es pour chaque frame
                frame_data = {
                    'step': step,
                    'nca_grid': grid_nca.cpu().numpy().copy(),
                    'target_grid': target_final.cpu().numpy().copy(),
                    'obstacle_mask': obstacle_mask.cpu().numpy().copy(),
                    'source_mask': source_mask.cpu().numpy().copy(),
                    'title': f"{title_prefix} ‚Äî √âtape {step+1}/{n_steps}"
                }
                frames.append(frame_data)

            # Sauvegarde des frames
            filename = f"{cfg.OUTPUT_DIR}/animation_{title_prefix.lower().replace(' ', '_')}.npy"
            np.save(filename, frames)
            print(f"üíæ Animation sauvegard√©e: {filename}")

    def plot_training_metrics(self, trainer: NCATrainer) -> None:
        """
        Graphiques des m√©triques d'entra√Ænement.
        """
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

        # Courbe de perte
        ax1.plot(trainer.loss_history, linewidth=2)
        ax1.set_xlabel("√âpoque")
        ax1.set_ylabel("Perte MSE")
        ax1.set_title("√âvolution de la perte")
        ax1.grid(True, alpha=0.3)
        ax1.set_yscale('log')

        # Courbe du learning rate
        ax2.plot(trainer.lr_history, linewidth=2, color='orange')
        ax2.set_xlabel("√âpoque")
        ax2.set_ylabel("Learning Rate")
        ax2.set_title("√âvolution du Learning Rate")
        ax2.grid(True, alpha=0.3)
        ax2.set_yscale('log')

        plt.tight_layout()

        if self.interactive:
            plt.show()
        else:
            plt.savefig(f"{cfg.OUTPUT_DIR}/training_metrics.png", dpi=150, bbox_inches='tight')
            print(f"üíæ M√©triques sauvegard√©es: {cfg.OUTPUT_DIR}/training_metrics.png")

        plt.close(fig)

# =============================================================================
# Ex√©cution principale
# =============================================================================

def main():
    """
    Fonction principale orchestrant tout le processus avec obstacles.
    """
    print("=" * 60)
    print("üß† Neural Cellular Automaton - Diffusion avec obstacles")
    print("=" * 60)

    # Cr√©ation du mod√®le et des syst√®mes associ√©s
    model = ImprovedNCA().to(cfg.DEVICE)
    trainer = NCATrainer(model)
    visualizer = NCAVisualizer()
    updater = NCAUpdater(model)

    print(f"üìä Param√®tres du mod√®le: {sum(p.numel() for p in model.parameters()):,}")

    # G√©n√©ration d'une s√©quence fixe pour la visualisation comparative
    # Utilise la vis_seed fournie en argument pour contr√¥ler la configuration de test
    vis_seed = args.vis_seed
    target_sequence_vis, source_mask_vis, obstacle_mask_vis = simulator.generate_sequence(
        n_steps=max(cfg.PREVIS_STEPS, cfg.POSTVIS_STEPS),
        size=cfg.GRID_SIZE,
        seed=vis_seed
    )

    print(f"üéØ Seed de visualisation: {vis_seed}")
    print(f"üß± Obstacles g√©n√©r√©s: {obstacle_mask_vis.sum().item()} cellules")

    # Visualisation avant entra√Ænement
    print("\nüé¨ Animation pr√©-entra√Ænement...")
    with torch.no_grad():
        model.eval()
        visualizer.animate_comparison(
            updater, target_sequence_vis, source_mask_vis, obstacle_mask_vis,
            "Avant entra√Ænement", cfg.PREVIS_STEPS
        )

    # Entra√Ænement
    print("\nüéØ Phase d'entra√Ænement...")
    trainer.train()

    # Visualisation apr√®s entra√Ænement
    print("\nüé¨ Animation post-entra√Ænement...")
    with torch.no_grad():
        model.eval()
        visualizer.animate_comparison(
            updater, target_sequence_vis, source_mask_vis, obstacle_mask_vis,
            "Apr√®s entra√Ænement", cfg.POSTVIS_STEPS
        )

    # Affichage des m√©triques
    print("\nüìà G√©n√©ration des graphiques de m√©triques...")
    visualizer.plot_training_metrics(trainer)

    # Sauvegarde du mod√®le avec informations sur les seeds
    if cfg.SAVE_ANIMATIONS:
        model_path = f"{cfg.OUTPUT_DIR}/nca_model.pth"
        torch.save({
            'model_state_dict': model.state_dict(),
            'config': cfg,
            'training_seed': cfg.SEED,
            'visualization_seed': vis_seed,
            'loss_history': trainer.loss_history,
            'lr_history': trainer.lr_history
        }, model_path)
        print(f"üíæ Mod√®le sauvegard√©: {model_path}")

    print("\n‚ú® Processus termin√© avec succ√®s!")
    print(f"üìù R√©sum√© des seeds utilis√©es:")
    print(f"   - Entra√Ænement: {cfg.SEED}")
    print(f"   - Visualisation: {vis_seed}")

if __name__ == "__main__":
    main()
